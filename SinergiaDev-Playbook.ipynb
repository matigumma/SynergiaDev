{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Sinergia Dev** playbook"
      ],
      "metadata": {
        "id": "GPWEhGa0m2SU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Openai Responses API"
      ],
      "metadata": {
        "id": "7Rg0qWBno1O4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- python install requirements"
      ],
      "metadata": {
        "id": "aUiDqKuHo8xO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UYfa5CfsoicL",
        "outputId": "a9d02f09-1dd9-42e0-f612-e40d65b499ab"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.66.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "# set env for openai key:\n",
        "\n",
        "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")"
      ],
      "metadata": {
        "id": "kiDdYIHeb--6"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "# Generate text from a simple prompt\n",
        "\n",
        "## ChatGPT LLM single call\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\"Escribe un cuento de buenas noches en una sola oración sobre un unicornio.\"\n",
        ")\n",
        "\n",
        "## print response output text\n",
        "print(\"response.output_text:\\n\")\n",
        "print(response.output_text)\n",
        "\n",
        "## debug full response object\n",
        "print(\"response object:\\n\")\n",
        "pprint.pprint(response.model_dump())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "P9h03_IfpSGE",
        "outputId": "0b1c90be-371f-4987-c584-6fb6397196d4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "En un bosque encantado bajo un cielo estrellado, un unicornio de brillante cuerno dorado danzaba entre las flores, llenando el aire de suaves susurros mágicos que arrullaban a todos los animales hasta que se quedaban dormidos, soñando con aventuras en mundos lejanos.\n",
            "response object:\n",
            "\n",
            "{'created_at': 1742693934.0,\n",
            " 'error': None,\n",
            " 'id': 'resp_67df662e9fe48192a9e673150b83a2c205de7011f3d2c940',\n",
            " 'incomplete_details': None,\n",
            " 'instructions': None,\n",
            " 'max_output_tokens': None,\n",
            " 'metadata': {},\n",
            " 'model': 'gpt-4o-mini-2024-07-18',\n",
            " 'object': 'response',\n",
            " 'output': [{'content': [{'annotations': [],\n",
            "                          'text': 'En un bosque encantado bajo un cielo '\n",
            "                                  'estrellado, un unicornio de brillante '\n",
            "                                  'cuerno dorado danzaba entre las flores, '\n",
            "                                  'llenando el aire de suaves susurros mágicos '\n",
            "                                  'que arrullaban a todos los animales hasta '\n",
            "                                  'que se quedaban dormidos, soñando con '\n",
            "                                  'aventuras en mundos lejanos.',\n",
            "                          'type': 'output_text'}],\n",
            "             'id': 'msg_67df662f10cc8192b4d988c73fd9a31105de7011f3d2c940',\n",
            "             'role': 'assistant',\n",
            "             'status': 'completed',\n",
            "             'type': 'message'}],\n",
            " 'parallel_tool_calls': True,\n",
            " 'previous_response_id': None,\n",
            " 'reasoning': {'effort': None, 'generate_summary': None},\n",
            " 'status': 'completed',\n",
            " 'store': True,\n",
            " 'temperature': 1.0,\n",
            " 'text': {'format': {'type': 'text'}},\n",
            " 'tool_choice': 'auto',\n",
            " 'tools': [],\n",
            " 'top_p': 1.0,\n",
            " 'truncation': 'disabled',\n",
            " 'usage': {'input_tokens': 41,\n",
            "           'input_tokens_details': {'cached_tokens': 0},\n",
            "           'output_tokens': 66,\n",
            "           'output_tokens_details': {'reasoning_tokens': 0},\n",
            "           'total_tokens': 107},\n",
            " 'user': None}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate text with instructions\n",
        "\n",
        "## ChatGPT LLM single call\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o\",\n",
        "    instructions=\"Your goals is to translate to english every user input\",\n",
        "    input=\"Escribe un cuento de buenas noches en una sola oración sobre un unicornio.\",\n",
        ")\n",
        "\n",
        "## print response output text\n",
        "print(\"response.output_text:\\n\")\n",
        "print(response.output_text)\n",
        "\n",
        "## debug full response object\n",
        "print(\"response object:\\n\")\n",
        "pprint.pprint(response.model_dump())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "HvzCmUkerDzi",
        "outputId": "b9caa0ff-c31c-4d09-a26e-90d3d89c22d5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "response.output_text:\n",
            "\n",
            "Once upon a time, a unicorn with a shimmering rainbow mane gently guided the stars across the night sky to help lull the world to sleep.\n",
            "response object:\n",
            "\n",
            "{'created_at': 1742694376.0,\n",
            " 'error': None,\n",
            " 'id': 'resp_67df67e81f248192bc34a81eb67c65f80527f92665842bd4',\n",
            " 'incomplete_details': None,\n",
            " 'instructions': 'Your goals is to translate to english every user input',\n",
            " 'max_output_tokens': None,\n",
            " 'metadata': {},\n",
            " 'model': 'gpt-4o-2024-08-06',\n",
            " 'object': 'response',\n",
            " 'output': [{'content': [{'annotations': [],\n",
            "                          'text': 'Once upon a time, a unicorn with a '\n",
            "                                  'shimmering rainbow mane gently guided the '\n",
            "                                  'stars across the night sky to help lull the '\n",
            "                                  'world to sleep.',\n",
            "                          'type': 'output_text'}],\n",
            "             'id': 'msg_67df67e86fbc8192a59ebf9eb925f7410527f92665842bd4',\n",
            "             'role': 'assistant',\n",
            "             'status': 'completed',\n",
            "             'type': 'message'}],\n",
            " 'parallel_tool_calls': True,\n",
            " 'previous_response_id': None,\n",
            " 'reasoning': {'effort': None, 'generate_summary': None},\n",
            " 'status': 'completed',\n",
            " 'store': True,\n",
            " 'temperature': 1.0,\n",
            " 'text': {'format': {'type': 'text'}},\n",
            " 'tool_choice': 'auto',\n",
            " 'tools': [],\n",
            " 'top_p': 1.0,\n",
            " 'truncation': 'disabled',\n",
            " 'usage': {'input_tokens': 55,\n",
            "           'input_tokens_details': {'cached_tokens': 0},\n",
            "           'output_tokens': 29,\n",
            "           'output_tokens_details': {'reasoning_tokens': 0},\n",
            "           'total_tokens': 84},\n",
            " 'user': None}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate text with messages using different roles\n",
        "\n",
        "## ChatGPT LLM with message history style (it will preserve instructions on history)\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=[\n",
        "        {\n",
        "            \"role\": \"developer\",\n",
        "            \"content\": \"Your goals is to translate to spanish every user input\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Are semicolons optional in JavaScript?\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "## print response output text\n",
        "print(\"response.output_text:\\n\")\n",
        "print(response.output_text)\n",
        "\n",
        "## debug full response object\n",
        "print(\"response object:\\n\")\n",
        "pprint.pprint(response.model_dump())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRIbvrqPxWJh",
        "outputId": "50cc73cb-ca46-4ee0-9354-0fa742b0f7cd"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "response.output_text:\n",
            "\n",
            "¿Son opcionales los puntos y coma en JavaScript?\n",
            "response object:\n",
            "\n",
            "{'created_at': 1742696160.0,\n",
            " 'error': None,\n",
            " 'id': 'resp_67df6ee020e0819287dd0e3440d2334801e4bf2825cab03a',\n",
            " 'incomplete_details': None,\n",
            " 'instructions': None,\n",
            " 'max_output_tokens': None,\n",
            " 'metadata': {},\n",
            " 'model': 'gpt-4o-mini-2024-07-18',\n",
            " 'object': 'response',\n",
            " 'output': [{'content': [{'annotations': [],\n",
            "                          'text': '¿Son opcionales los puntos y coma en '\n",
            "                                  'JavaScript?',\n",
            "                          'type': 'output_text'}],\n",
            "             'id': 'msg_67df6ee092808192bf4409fa423b50fb01e4bf2825cab03a',\n",
            "             'role': 'assistant',\n",
            "             'status': 'completed',\n",
            "             'type': 'message'}],\n",
            " 'parallel_tool_calls': True,\n",
            " 'previous_response_id': None,\n",
            " 'reasoning': {'effort': None, 'generate_summary': None},\n",
            " 'status': 'completed',\n",
            " 'store': True,\n",
            " 'temperature': 1.0,\n",
            " 'text': {'format': {'type': 'text'}},\n",
            " 'tool_choice': 'auto',\n",
            " 'tools': [],\n",
            " 'top_p': 1.0,\n",
            " 'truncation': 'disabled',\n",
            " 'usage': {'input_tokens': 48,\n",
            "           'input_tokens_details': {'cached_tokens': 0},\n",
            "           'output_tokens': 13,\n",
            "           'output_tokens_details': {'reasoning_tokens': 0},\n",
            "           'total_tokens': 61},\n",
            " 'user': None}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Structured Outputs"
      ],
      "metadata": {
        "id": "jst96GmlyzTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# structured output models support by:\n",
        "\n",
        "# gpt-4.5-preview-2025-02-27 and later\n",
        "# o3-mini-2025-1-31 and later\n",
        "# o1-2024-12-17 and later\n",
        "# gpt-4o-mini-2024-07-18 and later\n",
        "# gpt-4o-2024-08-06 and later\n",
        "\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o-2024-08-06\",\n",
        "    input=[\n",
        "        {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Matias and Jony are going to SinergIA-Dev on 25 Friday, march at 15hs.\"}\n",
        "    ],\n",
        "    text={\n",
        "        \"format\": {\n",
        "            \"type\": \"json_schema\",\n",
        "            \"name\": \"calendar_event\",\n",
        "            \"schema\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"name\": {\n",
        "                        \"type\": \"string\"\n",
        "                    },\n",
        "                    \"date\": {\n",
        "                        \"type\": \"string\"\n",
        "                    },\n",
        "                    \"participants\": {\n",
        "                        \"type\": \"array\",\n",
        "                        \"items\": {\n",
        "                            \"type\": \"string\"\n",
        "                        }\n",
        "                    },\n",
        "                },\n",
        "                \"required\": [\"name\", \"date\", \"participants\"],\n",
        "                \"additionalProperties\": False\n",
        "            },\n",
        "            \"strict\": True\n",
        "        }\n",
        "    }\n",
        ")\n",
        "\n",
        "event = json.loads(response.output_text)\n",
        "\n",
        "print(event)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiwAXtLSyxVs",
        "outputId": "c759f787-b0ff-422b-c021-72610b8cfb37"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'name': 'SinergIA-Dev', 'date': '2023-03-25T15:00:00', 'participants': ['Matias', 'Jony']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pprint\n",
        "\n",
        "# Structured Outputs for chain-of-thought math tutoring\n",
        "\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o-2024-08-06\",\n",
        "    input=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful math tutor. Guide the user through the solution step by step.\"},\n",
        "        {\"role\": \"user\", \"content\": \"how can I solve 8x + 7 = -23\"}\n",
        "    ],\n",
        "    text={\n",
        "        \"format\": {\n",
        "            \"type\": \"json_schema\",\n",
        "            \"name\": \"math_reasoning\",\n",
        "            \"schema\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"steps\": {\n",
        "                        \"type\": \"array\",\n",
        "                        \"items\": {\n",
        "                            \"type\": \"object\",\n",
        "                            \"properties\": {\n",
        "                                \"explanation\": { \"type\": \"string\" },\n",
        "                                \"output\": { \"type\": \"string\" }\n",
        "                            },\n",
        "                            \"required\": [\"explanation\", \"output\"],\n",
        "                            \"additionalProperties\": False\n",
        "                        }\n",
        "                    },\n",
        "                    \"final_answer\": { \"type\": \"string\" }\n",
        "                },\n",
        "                \"required\": [\"steps\", \"final_answer\"],\n",
        "                \"additionalProperties\": False\n",
        "            },\n",
        "            \"strict\": True\n",
        "        }\n",
        "    }\n",
        ")\n",
        "\n",
        "math_reasoning = json.loads(response.output_text)\n",
        "pprint.pprint(math_reasoning)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwKcmCPH0aqd",
        "outputId": "49294c06-48b6-4c52-a2fd-96aeb4782ba0"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'final_answer': 'x = -\\\\frac{15}{4}',\n",
            " 'steps': [{'explanation': \"Start by isolating the term with the variable 'x'. \"\n",
            "                           'We need to move the constant term on the left side '\n",
            "                           'to the right side. To do this, subtract 7 from '\n",
            "                           'both sides of the equation.',\n",
            "            'output': '8x + 7 - 7 = -23 - 7'},\n",
            "           {'explanation': 'This simplifies to:', 'output': '8x = -30'},\n",
            "           {'explanation': \"Next, solve for 'x' by dividing both sides of the \"\n",
            "                           'equation by 8.',\n",
            "            'output': '\\\\( x = \\\\frac{-30}{8} \\\\)'},\n",
            "           {'explanation': 'Simplify the fraction by dividing the numerator '\n",
            "                           'and the denominator by their greatest common '\n",
            "                           'divisor, which is 2.',\n",
            "            'output': '\\\\( x = \\\\frac{-15}{4} \\\\)'},\n",
            "           {'explanation': 'Thus, the solution to the equation is:',\n",
            "            'output': 'x = -\\\\frac{15}{4}'}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nYLXmhOCbYKy",
        "outputId": "dc976272-1500-4f14-bf56-c439b2c159b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.20)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.41 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.45)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.15)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.39)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# install langchain\n",
        "\n",
        "!pip install langchain\n",
        "!pip install -qU \"langchain[openai]\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "# define model to use\n",
        "model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
        "\n",
        "# message preparation:\n",
        "\n",
        "## using history messages:\n",
        "messages = [\n",
        "    SystemMessage(\"Translate the following from English into Spanish\"),\n",
        "    HumanMessage(\"hi! Im a developer trying to learn AI\"),\n",
        "]\n",
        "\n",
        "# LLM call\n",
        "\n",
        "## invoke chat completion\n",
        "response = model.invoke(messages)\n",
        "\n",
        "# print response text\n",
        "print(\"response.content:\\n\")\n",
        "print(response.content + \"\\n\")\n",
        "print(\"response object:\\n\")\n",
        "pprint.pprint(response.model_dump())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6-Cj8aGbj-A",
        "outputId": "a87c3fa6-67c2-418c-e566-5d28768dbda5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "response.content:\n",
            "\n",
            "¡Hola! Soy un desarrollador que está tratando de aprender sobre IA.\n",
            "\n",
            "response object:\n",
            "\n",
            "{'additional_kwargs': {'refusal': None},\n",
            " 'content': '¡Hola! Soy un desarrollador que está tratando de aprender sobre '\n",
            "            'IA.',\n",
            " 'example': False,\n",
            " 'id': 'run-6d050664-d16b-4c6b-827f-547a56ab17a3-0',\n",
            " 'invalid_tool_calls': [],\n",
            " 'name': None,\n",
            " 'response_metadata': {'finish_reason': 'stop',\n",
            "                       'id': 'chatcmpl-BE4TgDzmLvW32p12Wq7bFpTJMRnSu',\n",
            "                       'logprobs': None,\n",
            "                       'model_name': 'gpt-4o-mini-2024-07-18',\n",
            "                       'system_fingerprint': 'fp_b8bc95a0ac',\n",
            "                       'token_usage': {'completion_tokens': 16,\n",
            "                                       'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
            "                                                                     'audio_tokens': 0,\n",
            "                                                                     'reasoning_tokens': 0,\n",
            "                                                                     'rejected_prediction_tokens': 0},\n",
            "                                       'prompt_tokens': 27,\n",
            "                                       'prompt_tokens_details': {'audio_tokens': 0,\n",
            "                                                                 'cached_tokens': 0},\n",
            "                                       'total_tokens': 43}},\n",
            " 'tool_calls': [],\n",
            " 'type': 'ai',\n",
            " 'usage_metadata': {'input_token_details': {'audio': 0, 'cache_read': 0},\n",
            "                    'input_tokens': 27,\n",
            "                    'output_token_details': {'audio': 0, 'reasoning': 0},\n",
            "                    'output_tokens': 16,\n",
            "                    'total_tokens': 43}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# example for a dynamic template completion\n",
        "\n",
        "## using template with variables\n",
        "system_template = \"Translate the following from English into {language}\" # variable on template interpolated with {var_name}\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
        ")\n",
        "\n",
        "prompt = prompt_template.invoke({\"language\": \"Italian\", \"text\": \"hi! Please take the recommended actions to update your configuration\"})\n",
        "\n"
      ],
      "metadata": {
        "id": "hakqOW1PjREl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template_prompt = ChatPromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
        "\n",
        "chain = template_prompt | model\n",
        "response1 = chain.invoke({\"topic\": \"programming\"})\n",
        "print(response1.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6TUcu9DcXnD",
        "outputId": "ff9d7c3a-d09b-46fa-88f2-0bac1f0d22c3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why do programmers prefer dark mode?  \n",
            "\n",
            "Because light attracts bugs!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "\n",
        "pprint.pprint(response1.model_dump())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gtIdQ1hfQ6b",
        "outputId": "91712a1c-60eb-43c9-ee29-0040cf84cd11"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'additional_kwargs': {'refusal': None},\n",
            " 'content': 'Why do programmers prefer dark mode?  \\n'\n",
            "            '\\n'\n",
            "            'Because light attracts bugs!',\n",
            " 'example': False,\n",
            " 'id': 'run-f082ff71-da76-4769-bdbe-6d1b237dd666-0',\n",
            " 'invalid_tool_calls': [],\n",
            " 'name': None,\n",
            " 'response_metadata': {'finish_reason': 'stop',\n",
            "                       'id': 'chatcmpl-BE3qElWGd9rZe1lS6y28RiISSkMhz',\n",
            "                       'logprobs': None,\n",
            "                       'model_name': 'gpt-4o-mini-2024-07-18',\n",
            "                       'system_fingerprint': 'fp_b8bc95a0ac',\n",
            "                       'token_usage': {'completion_tokens': 14,\n",
            "                                       'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
            "                                                                     'audio_tokens': 0,\n",
            "                                                                     'reasoning_tokens': 0,\n",
            "                                                                     'rejected_prediction_tokens': 0},\n",
            "                                       'prompt_tokens': 13,\n",
            "                                       'prompt_tokens_details': {'audio_tokens': 0,\n",
            "                                                                 'cached_tokens': 0},\n",
            "                                       'total_tokens': 27}},\n",
            " 'tool_calls': [],\n",
            " 'type': 'ai',\n",
            " 'usage_metadata': {'input_token_details': {'audio': 0, 'cache_read': 0},\n",
            "                    'input_tokens': 13,\n",
            "                    'output_token_details': {'audio': 0, 'reasoning': 0},\n",
            "                    'output_tokens': 14,\n",
            "                    'total_tokens': 27}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4jLb43RLfqq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sinergia Dev** playbook"
      ],
      "metadata": {
        "id": "CpUc3rMFcjQ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Openai Responses API"
      ],
      "metadata": {
        "id": "quOWiBsgcjRA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- python install requirements"
      ],
      "metadata": {
        "id": "53KD6q_ycjRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "a9d02f09-1dd9-42e0-f612-e40d65b499ab",
        "id": "bJLsSTJxcjRA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.66.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "# set env for openai key:\n",
        "\n",
        "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")"
      ],
      "metadata": {
        "id": "P1jha6itcjRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "# Generate text from a simple prompt\n",
        "\n",
        "## ChatGPT LLM single call\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\"Escribe un cuento de buenas noches en una sola oración sobre un unicornio.\"\n",
        ")\n",
        "\n",
        "## print response output text\n",
        "print(\"response.output_text:\\n\")\n",
        "print(response.output_text)\n",
        "\n",
        "## debug full response object\n",
        "print(\"response object:\\n\")\n",
        "pprint.pprint(response.model_dump())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "0b1c90be-371f-4987-c584-6fb6397196d4",
        "id": "IskA7o0PcjRB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "En un bosque encantado bajo un cielo estrellado, un unicornio de brillante cuerno dorado danzaba entre las flores, llenando el aire de suaves susurros mágicos que arrullaban a todos los animales hasta que se quedaban dormidos, soñando con aventuras en mundos lejanos.\n",
            "response object:\n",
            "\n",
            "{'created_at': 1742693934.0,\n",
            " 'error': None,\n",
            " 'id': 'resp_67df662e9fe48192a9e673150b83a2c205de7011f3d2c940',\n",
            " 'incomplete_details': None,\n",
            " 'instructions': None,\n",
            " 'max_output_tokens': None,\n",
            " 'metadata': {},\n",
            " 'model': 'gpt-4o-mini-2024-07-18',\n",
            " 'object': 'response',\n",
            " 'output': [{'content': [{'annotations': [],\n",
            "                          'text': 'En un bosque encantado bajo un cielo '\n",
            "                                  'estrellado, un unicornio de brillante '\n",
            "                                  'cuerno dorado danzaba entre las flores, '\n",
            "                                  'llenando el aire de suaves susurros mágicos '\n",
            "                                  'que arrullaban a todos los animales hasta '\n",
            "                                  'que se quedaban dormidos, soñando con '\n",
            "                                  'aventuras en mundos lejanos.',\n",
            "                          'type': 'output_text'}],\n",
            "             'id': 'msg_67df662f10cc8192b4d988c73fd9a31105de7011f3d2c940',\n",
            "             'role': 'assistant',\n",
            "             'status': 'completed',\n",
            "             'type': 'message'}],\n",
            " 'parallel_tool_calls': True,\n",
            " 'previous_response_id': None,\n",
            " 'reasoning': {'effort': None, 'generate_summary': None},\n",
            " 'status': 'completed',\n",
            " 'store': True,\n",
            " 'temperature': 1.0,\n",
            " 'text': {'format': {'type': 'text'}},\n",
            " 'tool_choice': 'auto',\n",
            " 'tools': [],\n",
            " 'top_p': 1.0,\n",
            " 'truncation': 'disabled',\n",
            " 'usage': {'input_tokens': 41,\n",
            "           'input_tokens_details': {'cached_tokens': 0},\n",
            "           'output_tokens': 66,\n",
            "           'output_tokens_details': {'reasoning_tokens': 0},\n",
            "           'total_tokens': 107},\n",
            " 'user': None}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate text with instructions\n",
        "\n",
        "## ChatGPT LLM single call\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o\",\n",
        "    instructions=\"Your goals is to translate to english every user input\",\n",
        "    input=\"Escribe un cuento de buenas noches en una sola oración sobre un unicornio.\",\n",
        ")\n",
        "\n",
        "## print response output text\n",
        "print(\"response.output_text:\\n\")\n",
        "print(response.output_text)\n",
        "\n",
        "## debug full response object\n",
        "print(\"response object:\\n\")\n",
        "pprint.pprint(response.model_dump())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "b9caa0ff-c31c-4d09-a26e-90d3d89c22d5",
        "id": "LMBtLMC0cjRC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "response.output_text:\n",
            "\n",
            "Once upon a time, a unicorn with a shimmering rainbow mane gently guided the stars across the night sky to help lull the world to sleep.\n",
            "response object:\n",
            "\n",
            "{'created_at': 1742694376.0,\n",
            " 'error': None,\n",
            " 'id': 'resp_67df67e81f248192bc34a81eb67c65f80527f92665842bd4',\n",
            " 'incomplete_details': None,\n",
            " 'instructions': 'Your goals is to translate to english every user input',\n",
            " 'max_output_tokens': None,\n",
            " 'metadata': {},\n",
            " 'model': 'gpt-4o-2024-08-06',\n",
            " 'object': 'response',\n",
            " 'output': [{'content': [{'annotations': [],\n",
            "                          'text': 'Once upon a time, a unicorn with a '\n",
            "                                  'shimmering rainbow mane gently guided the '\n",
            "                                  'stars across the night sky to help lull the '\n",
            "                                  'world to sleep.',\n",
            "                          'type': 'output_text'}],\n",
            "             'id': 'msg_67df67e86fbc8192a59ebf9eb925f7410527f92665842bd4',\n",
            "             'role': 'assistant',\n",
            "             'status': 'completed',\n",
            "             'type': 'message'}],\n",
            " 'parallel_tool_calls': True,\n",
            " 'previous_response_id': None,\n",
            " 'reasoning': {'effort': None, 'generate_summary': None},\n",
            " 'status': 'completed',\n",
            " 'store': True,\n",
            " 'temperature': 1.0,\n",
            " 'text': {'format': {'type': 'text'}},\n",
            " 'tool_choice': 'auto',\n",
            " 'tools': [],\n",
            " 'top_p': 1.0,\n",
            " 'truncation': 'disabled',\n",
            " 'usage': {'input_tokens': 55,\n",
            "           'input_tokens_details': {'cached_tokens': 0},\n",
            "           'output_tokens': 29,\n",
            "           'output_tokens_details': {'reasoning_tokens': 0},\n",
            "           'total_tokens': 84},\n",
            " 'user': None}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate text with messages using different roles\n",
        "\n",
        "## ChatGPT LLM with message history style (it will preserve instructions on history)\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=[\n",
        "        {\n",
        "            \"role\": \"developer\",\n",
        "            \"content\": \"Your goals is to translate to spanish every user input\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Are semicolons optional in JavaScript?\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "## print response output text\n",
        "print(\"response.output_text:\\n\")\n",
        "print(response.output_text)\n",
        "\n",
        "## debug full response object\n",
        "print(\"response object:\\n\")\n",
        "pprint.pprint(response.model_dump())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50cc73cb-ca46-4ee0-9354-0fa742b0f7cd",
        "id": "SWi_p5g2cjRC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "response.output_text:\n",
            "\n",
            "¿Son opcionales los puntos y coma en JavaScript?\n",
            "response object:\n",
            "\n",
            "{'created_at': 1742696160.0,\n",
            " 'error': None,\n",
            " 'id': 'resp_67df6ee020e0819287dd0e3440d2334801e4bf2825cab03a',\n",
            " 'incomplete_details': None,\n",
            " 'instructions': None,\n",
            " 'max_output_tokens': None,\n",
            " 'metadata': {},\n",
            " 'model': 'gpt-4o-mini-2024-07-18',\n",
            " 'object': 'response',\n",
            " 'output': [{'content': [{'annotations': [],\n",
            "                          'text': '¿Son opcionales los puntos y coma en '\n",
            "                                  'JavaScript?',\n",
            "                          'type': 'output_text'}],\n",
            "             'id': 'msg_67df6ee092808192bf4409fa423b50fb01e4bf2825cab03a',\n",
            "             'role': 'assistant',\n",
            "             'status': 'completed',\n",
            "             'type': 'message'}],\n",
            " 'parallel_tool_calls': True,\n",
            " 'previous_response_id': None,\n",
            " 'reasoning': {'effort': None, 'generate_summary': None},\n",
            " 'status': 'completed',\n",
            " 'store': True,\n",
            " 'temperature': 1.0,\n",
            " 'text': {'format': {'type': 'text'}},\n",
            " 'tool_choice': 'auto',\n",
            " 'tools': [],\n",
            " 'top_p': 1.0,\n",
            " 'truncation': 'disabled',\n",
            " 'usage': {'input_tokens': 48,\n",
            "           'input_tokens_details': {'cached_tokens': 0},\n",
            "           'output_tokens': 13,\n",
            "           'output_tokens_details': {'reasoning_tokens': 0},\n",
            "           'total_tokens': 61},\n",
            " 'user': None}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Structured Outputs"
      ],
      "metadata": {
        "id": "0_wx1b6icjRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# structured output models support by:\n",
        "\n",
        "# gpt-4.5-preview-2025-02-27 and later\n",
        "# o3-mini-2025-1-31 and later\n",
        "# o1-2024-12-17 and later\n",
        "# gpt-4o-mini-2024-07-18 and later\n",
        "# gpt-4o-2024-08-06 and later\n",
        "\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o-2024-08-06\",\n",
        "    input=[\n",
        "        {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Matias and Jony are going to SinergIA-Dev on 25 Friday, march at 15hs.\"}\n",
        "    ],\n",
        "    text={\n",
        "        \"format\": {\n",
        "            \"type\": \"json_schema\",\n",
        "            \"name\": \"calendar_event\",\n",
        "            \"schema\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"name\": {\n",
        "                        \"type\": \"string\"\n",
        "                    },\n",
        "                    \"date\": {\n",
        "                        \"type\": \"string\"\n",
        "                    },\n",
        "                    \"participants\": {\n",
        "                        \"type\": \"array\",\n",
        "                        \"items\": {\n",
        "                            \"type\": \"string\"\n",
        "                        }\n",
        "                    },\n",
        "                },\n",
        "                \"required\": [\"name\", \"date\", \"participants\"],\n",
        "                \"additionalProperties\": False\n",
        "            },\n",
        "            \"strict\": True\n",
        "        }\n",
        "    }\n",
        ")\n",
        "\n",
        "event = json.loads(response.output_text)\n",
        "\n",
        "print(event)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c759f787-b0ff-422b-c021-72610b8cfb37",
        "id": "y9ktzbNhcjRC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'name': 'SinergIA-Dev', 'date': '2023-03-25T15:00:00', 'participants': ['Matias', 'Jony']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pprint\n",
        "\n",
        "# Structured Outputs for chain-of-thought math tutoring\n",
        "\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o-2024-08-06\",\n",
        "    input=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful math tutor. Guide the user through the solution step by step.\"},\n",
        "        {\"role\": \"user\", \"content\": \"how can I solve 8x + 7 = -23\"}\n",
        "    ],\n",
        "    text={\n",
        "        \"format\": {\n",
        "            \"type\": \"json_schema\",\n",
        "            \"name\": \"math_reasoning\",\n",
        "            \"schema\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"steps\": {\n",
        "                        \"type\": \"array\",\n",
        "                        \"items\": {\n",
        "                            \"type\": \"object\",\n",
        "                            \"properties\": {\n",
        "                                \"explanation\": { \"type\": \"string\" },\n",
        "                                \"output\": { \"type\": \"string\" }\n",
        "                            },\n",
        "                            \"required\": [\"explanation\", \"output\"],\n",
        "                            \"additionalProperties\": False\n",
        "                        }\n",
        "                    },\n",
        "                    \"final_answer\": { \"type\": \"string\" }\n",
        "                },\n",
        "                \"required\": [\"steps\", \"final_answer\"],\n",
        "                \"additionalProperties\": False\n",
        "            },\n",
        "            \"strict\": True\n",
        "        }\n",
        "    }\n",
        ")\n",
        "\n",
        "math_reasoning = json.loads(response.output_text)\n",
        "pprint.pprint(math_reasoning)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49294c06-48b6-4c52-a2fd-96aeb4782ba0",
        "id": "Nnuf4k8mcjRC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'final_answer': 'x = -\\\\frac{15}{4}',\n",
            " 'steps': [{'explanation': \"Start by isolating the term with the variable 'x'. \"\n",
            "                           'We need to move the constant term on the left side '\n",
            "                           'to the right side. To do this, subtract 7 from '\n",
            "                           'both sides of the equation.',\n",
            "            'output': '8x + 7 - 7 = -23 - 7'},\n",
            "           {'explanation': 'This simplifies to:', 'output': '8x = -30'},\n",
            "           {'explanation': \"Next, solve for 'x' by dividing both sides of the \"\n",
            "                           'equation by 8.',\n",
            "            'output': '\\\\( x = \\\\frac{-30}{8} \\\\)'},\n",
            "           {'explanation': 'Simplify the fraction by dividing the numerator '\n",
            "                           'and the denominator by their greatest common '\n",
            "                           'divisor, which is 2.',\n",
            "            'output': '\\\\( x = \\\\frac{-15}{4} \\\\)'},\n",
            "           {'explanation': 'Thus, the solution to the equation is:',\n",
            "            'output': 'x = -\\\\frac{15}{4}'}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "dc976272-1500-4f14-bf56-c439b2c159b6",
        "id": "S10THGtscjRC"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.20)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.41 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.45)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.15)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.39)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# install langchain\n",
        "\n",
        "!pip install langchain\n",
        "!pip install -qU \"langchain[openai]\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "# define model to use\n",
        "model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
        "\n",
        "# message preparation:\n",
        "\n",
        "## using history messages:\n",
        "messages = [\n",
        "    SystemMessage(\"Translate the following from English into Spanish\"),\n",
        "    HumanMessage(\"hi! Im a developer trying to learn AI\"),\n",
        "]\n",
        "\n",
        "# LLM call\n",
        "\n",
        "## invoke chat completion\n",
        "response = model.invoke(messages)\n",
        "\n",
        "# print response text\n",
        "print(\"response.content:\\n\")\n",
        "print(response.content + \"\\n\")\n",
        "print(\"response object:\\n\")\n",
        "pprint.pprint(response.model_dump())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a87c3fa6-67c2-418c-e566-5d28768dbda5",
        "id": "uWNd1FbFcjRD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "response.content:\n",
            "\n",
            "¡Hola! Soy un desarrollador que está tratando de aprender sobre IA.\n",
            "\n",
            "response object:\n",
            "\n",
            "{'additional_kwargs': {'refusal': None},\n",
            " 'content': '¡Hola! Soy un desarrollador que está tratando de aprender sobre '\n",
            "            'IA.',\n",
            " 'example': False,\n",
            " 'id': 'run-6d050664-d16b-4c6b-827f-547a56ab17a3-0',\n",
            " 'invalid_tool_calls': [],\n",
            " 'name': None,\n",
            " 'response_metadata': {'finish_reason': 'stop',\n",
            "                       'id': 'chatcmpl-BE4TgDzmLvW32p12Wq7bFpTJMRnSu',\n",
            "                       'logprobs': None,\n",
            "                       'model_name': 'gpt-4o-mini-2024-07-18',\n",
            "                       'system_fingerprint': 'fp_b8bc95a0ac',\n",
            "                       'token_usage': {'completion_tokens': 16,\n",
            "                                       'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
            "                                                                     'audio_tokens': 0,\n",
            "                                                                     'reasoning_tokens': 0,\n",
            "                                                                     'rejected_prediction_tokens': 0},\n",
            "                                       'prompt_tokens': 27,\n",
            "                                       'prompt_tokens_details': {'audio_tokens': 0,\n",
            "                                                                 'cached_tokens': 0},\n",
            "                                       'total_tokens': 43}},\n",
            " 'tool_calls': [],\n",
            " 'type': 'ai',\n",
            " 'usage_metadata': {'input_token_details': {'audio': 0, 'cache_read': 0},\n",
            "                    'input_tokens': 27,\n",
            "                    'output_token_details': {'audio': 0, 'reasoning': 0},\n",
            "                    'output_tokens': 16,\n",
            "                    'total_tokens': 43}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# example for a dynamic template completion\n",
        "\n",
        "## using template with variables\n",
        "system_template = \"Translate the following from English into {language}\" # variable on template interpolated with {var_name}\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
        ")\n",
        "\n",
        "prompt = prompt_template.invoke({\"language\": \"Italian\", \"text\": \"hi! Please take the recommended actions to update your configuration\"})\n",
        "\n"
      ],
      "metadata": {
        "id": "FT67Xxe8cjRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template_prompt = ChatPromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
        "\n",
        "chain = template_prompt | model\n",
        "response1 = chain.invoke({\"topic\": \"programming\"})\n",
        "print(response1.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff9d7c3a-d09b-46fa-88f2-0bac1f0d22c3",
        "id": "1XrdDIF8cjRD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why do programmers prefer dark mode?  \n",
            "\n",
            "Because light attracts bugs!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "\n",
        "pprint.pprint(response1.model_dump())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91712a1c-60eb-43c9-ee29-0040cf84cd11",
        "id": "5QMSNwZFcjRD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'additional_kwargs': {'refusal': None},\n",
            " 'content': 'Why do programmers prefer dark mode?  \\n'\n",
            "            '\\n'\n",
            "            'Because light attracts bugs!',\n",
            " 'example': False,\n",
            " 'id': 'run-f082ff71-da76-4769-bdbe-6d1b237dd666-0',\n",
            " 'invalid_tool_calls': [],\n",
            " 'name': None,\n",
            " 'response_metadata': {'finish_reason': 'stop',\n",
            "                       'id': 'chatcmpl-BE3qElWGd9rZe1lS6y28RiISSkMhz',\n",
            "                       'logprobs': None,\n",
            "                       'model_name': 'gpt-4o-mini-2024-07-18',\n",
            "                       'system_fingerprint': 'fp_b8bc95a0ac',\n",
            "                       'token_usage': {'completion_tokens': 14,\n",
            "                                       'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
            "                                                                     'audio_tokens': 0,\n",
            "                                                                     'reasoning_tokens': 0,\n",
            "                                                                     'rejected_prediction_tokens': 0},\n",
            "                                       'prompt_tokens': 13,\n",
            "                                       'prompt_tokens_details': {'audio_tokens': 0,\n",
            "                                                                 'cached_tokens': 0},\n",
            "                                       'total_tokens': 27}},\n",
            " 'tool_calls': [],\n",
            " 'type': 'ai',\n",
            " 'usage_metadata': {'input_token_details': {'audio': 0, 'cache_read': 0},\n",
            "                    'input_tokens': 13,\n",
            "                    'output_token_details': {'audio': 0, 'reasoning': 0},\n",
            "                    'output_tokens': 14,\n",
            "                    'total_tokens': 27}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aDSzL-XDcjRD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}