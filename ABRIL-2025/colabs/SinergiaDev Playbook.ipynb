{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPWEhGa0m2SU"
      },
      "source": [
        "**Sinergia Dev** playbook base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Rg0qWBno1O4"
      },
      "source": [
        "# Openai Responses API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUiDqKuHo8xO"
      },
      "source": [
        "- python install requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UYfa5CfsoicL",
        "outputId": "15c7ca6c-fae1-4c12-a5df-603a3d0706b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in ./.venv/lib/python3.11/site-packages (1.76.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.11/site-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.11/site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.11/site-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.11/site-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in ./.venv/lib/python3.11/site-packages (from openai) (2.11.3)\n",
            "Requirement already satisfied: sniffio in ./.venv/lib/python3.11/site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.11/site-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in ./.venv/lib/python3.11/site-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiDdYIHeb--6",
        "outputId": "297b111a-31c7-4e0e-9ed6-c7f6599a55aa"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "# set env for openai key:\n",
        "\n",
        "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "P9h03_IfpSGE",
        "outputId": "0b1c90be-371f-4987-c584-6fb6397196d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "response.output_text:\n",
            "\n",
            "Una noche estrellada, un unicornio llamado Luno iluminÃ³ el bosque con su cuerno brillante mientras danzaba entre los sueÃ±os de los niÃ±os, asegurando que cada uno despertara con una sonrisa en el corazÃ³n.\n",
            "response object:\n",
            "\n",
            "{'created_at': 1745446012.0,\n",
            " 'error': None,\n",
            " 'id': 'resp_6809647cd4248192af35ade638330f1807e15694723ac3b9',\n",
            " 'incomplete_details': None,\n",
            " 'instructions': None,\n",
            " 'max_output_tokens': None,\n",
            " 'metadata': {},\n",
            " 'model': 'gpt-4o-mini-2024-07-18',\n",
            " 'object': 'response',\n",
            " 'output': [{'content': [{'annotations': [],\n",
            "                          'text': 'Una noche estrellada, un unicornio llamado '\n",
            "                                  'Luno iluminÃ³ el bosque con su cuerno '\n",
            "                                  'brillante mientras danzaba entre los sueÃ±os '\n",
            "                                  'de los niÃ±os, asegurando que cada uno '\n",
            "                                  'despertara con una sonrisa en el corazÃ³n.',\n",
            "                          'type': 'output_text'}],\n",
            "             'id': 'msg_6809647d545481928a7b478c14ddbc9707e15694723ac3b9',\n",
            "             'role': 'assistant',\n",
            "             'status': 'completed',\n",
            "             'type': 'message'}],\n",
            " 'parallel_tool_calls': True,\n",
            " 'previous_response_id': None,\n",
            " 'reasoning': {'effort': None, 'generate_summary': None, 'summary': None},\n",
            " 'service_tier': 'default',\n",
            " 'status': 'completed',\n",
            " 'store': True,\n",
            " 'temperature': 1.0,\n",
            " 'text': {'format': {'type': 'text'}},\n",
            " 'tool_choice': 'auto',\n",
            " 'tools': [],\n",
            " 'top_p': 1.0,\n",
            " 'truncation': 'disabled',\n",
            " 'usage': {'input_tokens': 23,\n",
            "           'input_tokens_details': {'cached_tokens': 0},\n",
            "           'output_tokens': 47,\n",
            "           'output_tokens_details': {'reasoning_tokens': 0},\n",
            "           'total_tokens': 70},\n",
            " 'user': None}\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "import pprint\n",
        "client = OpenAI()\n",
        "\n",
        "# GENERA UN TEXTO EN BASE A UN PROMPT SIMPLE \n",
        "# NIVEL 1\n",
        "\n",
        "## ChatGPT LLM single call\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\"Escribe un cuento de buenas noches en una sola oraciÃ³n sobre un unicornio.\"\n",
        ")\n",
        "\n",
        "## print response output text\n",
        "print(\"response.output_text:\\n\")\n",
        "pprint.pprint(response.output_text)\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "## debug full response object\n",
        "print(\"response object:\\n\")\n",
        "pprint.pprint(response.model_dump())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "HvzCmUkerDzi",
        "outputId": "b9caa0ff-c31c-4d09-a26e-90d3d89c22d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "response.output_text:\n",
            "\n",
            "Write a one-sentence bedtime story about a unicorn.\n",
            "\n",
            "\n",
            "\n",
            "response object:\n",
            "\n",
            "{'created_at': 1745447673.0,\n",
            " 'error': None,\n",
            " 'id': 'resp_68096af9513c81929ea75ee392a952750ba1855e4c491965',\n",
            " 'incomplete_details': None,\n",
            " 'instructions': 'You are an english translator. User will write a prompt. '\n",
            "                 'Your goals is to translate the user prompt',\n",
            " 'max_output_tokens': None,\n",
            " 'metadata': {},\n",
            " 'model': 'gpt-4o-2024-08-06',\n",
            " 'object': 'response',\n",
            " 'output': [{'content': [{'annotations': [],\n",
            "                          'text': 'Write a one-sentence bedtime story about a '\n",
            "                                  'unicorn.',\n",
            "                          'type': 'output_text'}],\n",
            "             'id': 'msg_68096af9d09881928f3adc91d67b24190ba1855e4c491965',\n",
            "             'role': 'assistant',\n",
            "             'status': 'completed',\n",
            "             'type': 'message'}],\n",
            " 'parallel_tool_calls': True,\n",
            " 'previous_response_id': None,\n",
            " 'reasoning': {'effort': None, 'generate_summary': None, 'summary': None},\n",
            " 'service_tier': 'default',\n",
            " 'status': 'completed',\n",
            " 'store': True,\n",
            " 'temperature': 1.0,\n",
            " 'text': {'format': {'type': 'text'}},\n",
            " 'tool_choice': 'auto',\n",
            " 'tools': [],\n",
            " 'top_p': 1.0,\n",
            " 'truncation': 'disabled',\n",
            " 'usage': {'input_tokens': 47,\n",
            "           'input_tokens_details': {'cached_tokens': 0},\n",
            "           'output_tokens': 12,\n",
            "           'output_tokens_details': {'reasoning_tokens': 0},\n",
            "           'total_tokens': 59},\n",
            " 'user': None}\n"
          ]
        }
      ],
      "source": [
        "# GENERA UN TEXTO CON UN PROMPT SIMPLE PERO AGREGANDOLE VARIABLES ESTATICAS (INSTRUCCIONES)\n",
        "# NIVEL 2\n",
        "\n",
        "## ChatGPT LLM single call\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o\", # \"gpt-4o-mini\" no entiende las instrucciones...\n",
        "    instructions=\"You are an english translator. User will write a prompt. Your goals is to translate the user prompt\", # estas son variables estaticas tambien\n",
        "    input=\"Escribe un cuento de buenas noches en una sola oraciÃ³n sobre un unicornio.\",\n",
        ")\n",
        "\n",
        "## print response output text\n",
        "print(\"response.output_text:\\n\")\n",
        "pprint.pprint(response.output_text)\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "## debug full response object\n",
        "print(\"response object:\\n\")\n",
        "pprint.pprint(response.model_dump())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRIbvrqPxWJh",
        "outputId": "50cc73cb-ca46-4ee0-9354-0fa742b0f7cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Â¡Claro! AquÃ­ tienes uno:\n",
            "\n",
            "Â¿Por quÃ© los programadores prefieren el cafÃ© al tÃ©?\n",
            "\n",
            "Porque el tÃ© tiene demasiados \"bugs\". â˜•ğŸ›\n",
            "\n",
            "Espero que te haya sacado una sonrisa. Â¡Si quieres otro, avÃ­same!\n",
            "\n",
            "\n",
            "\n",
            "Â¡Claro! El chiste juega con dos conceptos:\n",
            "\n",
            "1. **CafÃ© vs. TÃ©**: Es un estereotipo en la cultura de los programadores que muchos prefieren el cafÃ©, especialmente por su cafeÃ­na, que los ayuda a mantenerse despiertos durante largas horas de codificaciÃ³n.\n",
            "\n",
            "2. **Bugs**: En programaciÃ³n, un \"bug\" es un error o falla en el cÃ³digo. La broma implica que el tÃ© \"tiene demasiados bugs\", insinuando que podrÃ­a ser menos efectivo o mÃ¡s problemÃ¡tico, como un programa lleno de errores.\n",
            "\n",
            "La clave estÃ¡ en la conexiÃ³n entre el tÃ©rmino tÃ©cnico (\"bugs\") y la idea de que el tÃ© es menos deseable. Es un juego de palabras que combina lo cotidiano con el mundo de la programaciÃ³n, lo que suele generar una sonrisa entre quienes estÃ¡n familiarizados con esos conceptos. Â¡Espero que esto aclare la broma!\n",
            "\n",
            "\n",
            "\n",
            "response object:\n",
            "\n",
            "{'created_at': 1745448939.0,\n",
            " 'error': None,\n",
            " 'id': 'resp_68096febada08192abd41d34457a54c904cd980b77862b79',\n",
            " 'incomplete_details': None,\n",
            " 'instructions': None,\n",
            " 'max_output_tokens': None,\n",
            " 'metadata': {},\n",
            " 'model': 'gpt-4o-mini-2024-07-18',\n",
            " 'object': 'response',\n",
            " 'output': [{'content': [{'annotations': [],\n",
            "                          'text': 'Â¡Claro! AquÃ­ tienes uno:\\n'\n",
            "                                  '\\n'\n",
            "                                  'Â¿Por quÃ© los programadores prefieren el '\n",
            "                                  'cafÃ© al tÃ©?\\n'\n",
            "                                  '\\n'\n",
            "                                  'Porque el tÃ© tiene demasiados \"bugs\". â˜•ğŸ›\\n'\n",
            "                                  '\\n'\n",
            "                                  'Espero que te haya sacado una sonrisa. Â¡Si '\n",
            "                                  'quieres otro, avÃ­same!',\n",
            "                          'type': 'output_text'}],\n",
            "             'id': 'msg_68096febff448192830cebd25eaa1a4604cd980b77862b79',\n",
            "             'role': 'assistant',\n",
            "             'status': 'completed',\n",
            "             'type': 'message'}],\n",
            " 'parallel_tool_calls': True,\n",
            " 'previous_response_id': None,\n",
            " 'reasoning': {'effort': None, 'generate_summary': None, 'summary': None},\n",
            " 'service_tier': 'default',\n",
            " 'status': 'completed',\n",
            " 'store': True,\n",
            " 'temperature': 1.0,\n",
            " 'text': {'format': {'type': 'text'}},\n",
            " 'tool_choice': 'auto',\n",
            " 'tools': [],\n",
            " 'top_p': 1.0,\n",
            " 'truncation': 'disabled',\n",
            " 'usage': {'input_tokens': 15,\n",
            "           'input_tokens_details': {'cached_tokens': 0},\n",
            "           'output_tokens': 52,\n",
            "           'output_tokens_details': {'reasoning_tokens': 0},\n",
            "           'total_tokens': 67},\n",
            " 'user': None}\n",
            "\n",
            "\n",
            "\n",
            "second_response object:\n",
            "\n",
            "{'created_at': 1745448941.0,\n",
            " 'error': None,\n",
            " 'id': 'resp_68096fed2e008192819641bd69e8fa8c04cd980b77862b79',\n",
            " 'incomplete_details': None,\n",
            " 'instructions': None,\n",
            " 'max_output_tokens': None,\n",
            " 'metadata': {},\n",
            " 'model': 'gpt-4o-mini-2024-07-18',\n",
            " 'object': 'response',\n",
            " 'output': [{'content': [{'annotations': [],\n",
            "                          'text': 'Â¡Claro! El chiste juega con dos conceptos:\\n'\n",
            "                                  '\\n'\n",
            "                                  '1. **CafÃ© vs. TÃ©**: Es un estereotipo en la '\n",
            "                                  'cultura de los programadores que muchos '\n",
            "                                  'prefieren el cafÃ©, especialmente por su '\n",
            "                                  'cafeÃ­na, que los ayuda a mantenerse '\n",
            "                                  'despiertos durante largas horas de '\n",
            "                                  'codificaciÃ³n.\\n'\n",
            "                                  '\\n'\n",
            "                                  '2. **Bugs**: En programaciÃ³n, un \"bug\" es '\n",
            "                                  'un error o falla en el cÃ³digo. La broma '\n",
            "                                  'implica que el tÃ© \"tiene demasiados bugs\", '\n",
            "                                  'insinuando que podrÃ­a ser menos efectivo o '\n",
            "                                  'mÃ¡s problemÃ¡tico, como un programa lleno de '\n",
            "                                  'errores.\\n'\n",
            "                                  '\\n'\n",
            "                                  'La clave estÃ¡ en la conexiÃ³n entre el '\n",
            "                                  'tÃ©rmino tÃ©cnico (\"bugs\") y la idea de que '\n",
            "                                  'el tÃ© es menos deseable. Es un juego de '\n",
            "                                  'palabras que combina lo cotidiano con el '\n",
            "                                  'mundo de la programaciÃ³n, lo que suele '\n",
            "                                  'generar una sonrisa entre quienes estÃ¡n '\n",
            "                                  'familiarizados con esos conceptos. Â¡Espero '\n",
            "                                  'que esto aclare la broma!',\n",
            "                          'type': 'output_text'}],\n",
            "             'id': 'msg_68096fed80848192b1d55a2f4db1732204cd980b77862b79',\n",
            "             'role': 'assistant',\n",
            "             'status': 'completed',\n",
            "             'type': 'message'}],\n",
            " 'parallel_tool_calls': True,\n",
            " 'previous_response_id': 'resp_68096febada08192abd41d34457a54c904cd980b77862b79',\n",
            " 'reasoning': {'effort': None, 'generate_summary': None, 'summary': None},\n",
            " 'service_tier': 'default',\n",
            " 'status': 'completed',\n",
            " 'store': True,\n",
            " 'temperature': 1.0,\n",
            " 'text': {'format': {'type': 'text'}},\n",
            " 'tool_choice': 'auto',\n",
            " 'tools': [],\n",
            " 'top_p': 1.0,\n",
            " 'truncation': 'disabled',\n",
            " 'usage': {'input_tokens': 82,\n",
            "           'input_tokens_details': {'cached_tokens': 0},\n",
            "           'output_tokens': 183,\n",
            "           'output_tokens_details': {'reasoning_tokens': 0},\n",
            "           'total_tokens': 265},\n",
            " 'user': None}\n"
          ]
        }
      ],
      "source": [
        "# GENERA UN TEXTO CON UN history messages USANDO DIFERENTES ROLES (developer, user, assistant)\n",
        "# MANEJO DEL CONTEXTO...\n",
        "\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\"contame un chiste de programadores\",\n",
        ")\n",
        "print(response.output_text)\n",
        "print(\"\\n\\n\")\n",
        "second_response = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    previous_response_id=response.id, # esta es la forma de persistir el puntero del historial entre llamadas\n",
        "    input=[{\"role\": \"user\", \"content\": \"explicame porque es gracioso.\"}],\n",
        ")\n",
        "print(second_response.output_text)\n",
        "\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "## debug full response object\n",
        "print(\"response object:\\n\")\n",
        "pprint.pprint(response.model_dump())\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "## debug full response object\n",
        "print(\"second_response object:\\n\")\n",
        "pprint.pprint(second_response.model_dump())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jst96GmlyzTx"
      },
      "source": [
        "# Structured Outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiwAXtLSyxVs",
        "outputId": "c759f787-b0ff-422b-c021-72610b8cfb37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'event_name': 'SinergIA-Dev', 'date': '24 April 2023', 'participants': ['Matias', 'Jony']}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# GENERA UN JSON EN BASE A UNA ESTRUCTURA json DADA\n",
        "# NIVEL 2\n",
        "\n",
        "# structured output models support by:\n",
        "\n",
        "# gpt-4.5-preview-2025-02-27 and later\n",
        "# o3-mini-2025-1-31 and later\n",
        "# o1-2024-12-17 and later\n",
        "# gpt-4o-mini-2024-07-18 and later\n",
        "# gpt-4o-2024-08-06 and later\n",
        "\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o-2024-08-06\",\n",
        "    input=[\n",
        "        {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Matias and Jony are going to SinergIA-Dev on 24 thursday, april at 15hs.\"}\n",
        "    ],\n",
        "    text={\n",
        "        \"format\": {\n",
        "            \"type\": \"json_schema\",\n",
        "            \"name\": \"calendar_event\",\n",
        "            \"schema\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"event_name\": {\n",
        "                        \"type\": \"string\"\n",
        "                    },\n",
        "                    \"date\": {\n",
        "                        \"type\": \"string\",\n",
        "                    },\n",
        "                    \"participants\": {\n",
        "                        \"type\": \"array\",\n",
        "                        \"items\": {\n",
        "                            \"type\": \"string\"\n",
        "                        }\n",
        "                    },\n",
        "                },\n",
        "                \"required\": [\"event_name\", \"date\", \"participants\"],\n",
        "                \"additionalProperties\": False\n",
        "            },\n",
        "            \"strict\": True\n",
        "        }\n",
        "    }\n",
        ")\n",
        "\n",
        "event = json.loads(response.output_text)\n",
        "\n",
        "pprint.pprint(event)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwKcmCPH0aqd",
        "outputId": "49294c06-48b6-4c52-a2fd-96aeb4782ba0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'final_answer': 'x = -\\\\frac{15}{4}',\n",
            " 'steps': [{'explanation': \"Start by isolating the term with the variable 'x'. \"\n",
            "                           'We need to move the constant term on the left side '\n",
            "                           'to the right side. To do this, subtract 7 from '\n",
            "                           'both sides of the equation.',\n",
            "            'output': '8x + 7 - 7 = -23 - 7'},\n",
            "           {'explanation': 'This simplifies to:', 'output': '8x = -30'},\n",
            "           {'explanation': \"Next, solve for 'x' by dividing both sides of the \"\n",
            "                           'equation by 8.',\n",
            "            'output': '\\\\( x = \\\\frac{-30}{8} \\\\)'},\n",
            "           {'explanation': 'Simplify the fraction by dividing the numerator '\n",
            "                           'and the denominator by their greatest common '\n",
            "                           'divisor, which is 2.',\n",
            "            'output': '\\\\( x = \\\\frac{-15}{4} \\\\)'},\n",
            "           {'explanation': 'Thus, the solution to the equation is:',\n",
            "            'output': 'x = -\\\\frac{15}{4}'}]}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import pprint\n",
        "\n",
        "# Structured Outputs for chain-of-thought math tutoring\n",
        "\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o-2024-08-06\",\n",
        "    input=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful math tutor. Guide the user through the solution step by step.\"},\n",
        "        {\"role\": \"user\", \"content\": \"how can I solve 8x + 7 = -23\"}\n",
        "    ],\n",
        "    text={\n",
        "        \"format\": {\n",
        "            \"type\": \"json_schema\",\n",
        "            \"name\": \"math_reasoning\",\n",
        "            \"schema\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"steps\": {\n",
        "                        \"type\": \"array\",\n",
        "                        \"items\": {\n",
        "                            \"type\": \"object\",\n",
        "                            \"properties\": {\n",
        "                                \"explanation\": { \"type\": \"string\" },\n",
        "                                \"output\": { \"type\": \"string\" }\n",
        "                            },\n",
        "                            \"required\": [\"explanation\", \"output\"],\n",
        "                            \"additionalProperties\": False\n",
        "                        }\n",
        "                    },\n",
        "                    \"final_answer\": { \"type\": \"string\" }\n",
        "                },\n",
        "                \"required\": [\"steps\", \"final_answer\"],\n",
        "                \"additionalProperties\": False\n",
        "            },\n",
        "            \"strict\": True\n",
        "        }\n",
        "    }\n",
        ")\n",
        "\n",
        "math_reasoning = json.loads(response.output_text)\n",
        "pprint.pprint(math_reasoning)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "0_wx1b6icjRC",
        "R9EqlFSZ7KwI",
        "1ze4WZy6BXAm",
        "WO2VNtBAv3rw"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "347559df903540dd8ff69da3e85ec63b": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_79315cdbf90341ed97d2c17b8f0b7051",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">â–°â–°â–°â–°â–±â–±â–±</span> Thinking...\n<span style=\"color: #008080; text-decoration-color: #008080\">â”â” Message â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“</span>\n<span style=\"color: #008080; text-decoration-color: #008080\">â”ƒ</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">â”ƒ</span>\n<span style=\"color: #008080; text-decoration-color: #008080\">â”ƒ</span> <span style=\"color: #008000; text-decoration-color: #008000\">Show me a list of title from top 5 most recent story from Hacker News</span>                                           <span style=\"color: #008080; text-decoration-color: #008080\">â”ƒ</span>\n<span style=\"color: #008080; text-decoration-color: #008080\">â”ƒ</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">â”ƒ</span>\n<span style=\"color: #008080; text-decoration-color: #008080\">â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›</span>\n<span style=\"color: #808000; text-decoration-color: #808000\">â”â” Tool Calls â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“</span>\n<span style=\"color: #808000; text-decoration-color: #808000\">â”ƒ</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”ƒ</span>\n<span style=\"color: #808000; text-decoration-color: #808000\">â”ƒ</span> â€¢ get_top_hackernews_stories(num_stories=5)                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">â”ƒ</span>\n<span style=\"color: #808000; text-decoration-color: #808000\">â”ƒ</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”ƒ</span>\n<span style=\"color: #808000; text-decoration-color: #808000\">â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">â”â” Response (7.3s) â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span> Here are the top 5 most recent stories from Hacker News:                                                        <span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">OpenAI adds MCP support to Agents SDK</span>                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span><a href=\"https://openai.github.io/openai-agents-python/mcp/\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; text-decoration: underline\">Read more</span></a>                                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">Debian bookworm live images now reproducible</span>                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span><a href=\"https://lwn.net/Articles/1015402/\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; text-decoration: underline\">Read more</span></a>                                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 3 </span><span style=\"font-weight: bold\">The Mysterious Flow of Fluid in the Brain</span>                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span><a href=\"https://www.quantamagazine.org/the-mysterious-flow-of-fluid-in-the-brain-20250326/\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; text-decoration: underline\">Read more</span></a>                                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 4 </span><span style=\"font-weight: bold\">A love letter to the CSV format</span>                                                                              <span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span><a href=\"https://github.com/medialab/xan/blob/master/docs/LOVE_LETTER.md\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; text-decoration: underline\">Read more</span></a>                                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 5 </span><span style=\"font-weight: bold\">Building a Linux Container Runtime from Scratch</span>                                                              <span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span><a href=\"https://edera.dev/stories/styrolite\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; text-decoration: underline\">Read more</span></a>                                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span> Stay tuned for more tech tidbits! ğŸ–¥ï¸ğŸ”                                                                           <span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›</span>\n</pre>\n",
                  "text/plain": "\u001b[32mâ–°â–°â–°â–°â–±â–±â–±\u001b[0m Thinking...\n\u001b[36mâ”â”\u001b[0m\u001b[36m Message \u001b[0m\u001b[36mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[36mâ”â”“\u001b[0m\n\u001b[36mâ”ƒ\u001b[0m                                                                                                                 \u001b[36mâ”ƒ\u001b[0m\n\u001b[36mâ”ƒ\u001b[0m \u001b[32mShow me a list of title from top 5 most recent story from Hacker News\u001b[0m                                           \u001b[36mâ”ƒ\u001b[0m\n\u001b[36mâ”ƒ\u001b[0m                                                                                                                 \u001b[36mâ”ƒ\u001b[0m\n\u001b[36mâ”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›\u001b[0m\n\u001b[33mâ”â”\u001b[0m\u001b[33m Tool Calls \u001b[0m\u001b[33mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[33mâ”â”“\u001b[0m\n\u001b[33mâ”ƒ\u001b[0m                                                                                                                 \u001b[33mâ”ƒ\u001b[0m\n\u001b[33mâ”ƒ\u001b[0m â€¢ get_top_hackernews_stories(num_stories=5)                                                                     \u001b[33mâ”ƒ\u001b[0m\n\u001b[33mâ”ƒ\u001b[0m                                                                                                                 \u001b[33mâ”ƒ\u001b[0m\n\u001b[33mâ”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›\u001b[0m\n\u001b[34mâ”â”\u001b[0m\u001b[34m Response (7.3s) \u001b[0m\u001b[34mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[34mâ”â”“\u001b[0m\n\u001b[34mâ”ƒ\u001b[0m                                                                                                                 \u001b[34mâ”ƒ\u001b[0m\n\u001b[34mâ”ƒ\u001b[0m Here are the top 5 most recent stories from Hacker News:                                                        \u001b[34mâ”ƒ\u001b[0m\n\u001b[34mâ”ƒ\u001b[0m                                                                                                                 \u001b[34mâ”ƒ\u001b[0m\n\u001b[34mâ”ƒ\u001b[0m \u001b[1;33m 1 \u001b[0m\u001b[1mOpenAI adds MCP support to Agents SDK\u001b[0m                                                                        \u001b[34mâ”ƒ\u001b[0m\n\u001b[34mâ”ƒ\u001b[0m \u001b[1;33m   \u001b[0m\u001b]8;id=501521;https://openai.github.io/openai-agents-python/mcp/\u001b\\\u001b[4;34mRead more\u001b[0m\u001b]8;;\u001b\\                                                                                                    \u001b[34mâ”ƒ\u001b[0m\n\u001b[34mâ”ƒ\u001b[0m \u001b[1;33m 2 \u001b[0m\u001b[1mDebian bookworm live images now reproducible\u001b[0m                                                                 \u001b[34mâ”ƒ\u001b[0m\n\u001b[34mâ”ƒ\u001b[0m \u001b[1;33m   \u001b[0m\u001b]8;id=698136;https://lwn.net/Articles/1015402/\u001b\\\u001b[4;34mRead more\u001b[0m\u001b]8;;\u001b\\                                                                                                    \u001b[34mâ”ƒ\u001b[0m\n\u001b[34mâ”ƒ\u001b[0m \u001b[1;33m 3 \u001b[0m\u001b[1mThe Mysterious Flow of Fluid in the Brain\u001b[0m                                                                    \u001b[34mâ”ƒ\u001b[0m\n\u001b[34mâ”ƒ\u001b[0m \u001b[1;33m   \u001b[0m\u001b]8;id=599249;https://www.quantamagazine.org/the-mysterious-flow-of-fluid-in-the-brain-20250326/\u001b\\\u001b[4;34mRead more\u001b[0m\u001b]8;;\u001b\\                                                                                                    \u001b[34mâ”ƒ\u001b[0m\n\u001b[34mâ”ƒ\u001b[0m \u001b[1;33m 4 \u001b[0m\u001b[1mA love letter to the CSV format\u001b[0m                                                                              \u001b[34mâ”ƒ\u001b[0m\n\u001b[34mâ”ƒ\u001b[0m \u001b[1;33m   \u001b[0m\u001b]8;id=801033;https://github.com/medialab/xan/blob/master/docs/LOVE_LETTER.md\u001b\\\u001b[4;34mRead more\u001b[0m\u001b]8;;\u001b\\                                                                                                    \u001b[34mâ”ƒ\u001b[0m\n\u001b[34mâ”ƒ\u001b[0m \u001b[1;33m 5 \u001b[0m\u001b[1mBuilding a Linux Container Runtime from Scratch\u001b[0m                                                              \u001b[34mâ”ƒ\u001b[0m\n\u001b[34mâ”ƒ\u001b[0m \u001b[1;33m   \u001b[0m\u001b]8;id=180920;https://edera.dev/stories/styrolite\u001b\\\u001b[4;34mRead more\u001b[0m\u001b]8;;\u001b\\                                                                                                    \u001b[34mâ”ƒ\u001b[0m\n\u001b[34mâ”ƒ\u001b[0m                                                                                                                 \u001b[34mâ”ƒ\u001b[0m\n\u001b[34mâ”ƒ\u001b[0m Stay tuned for more tech tidbits! ğŸ–¥ï¸ğŸ”                                                                           \u001b[34mâ”ƒ\u001b[0m\n\u001b[34mâ”ƒ\u001b[0m                                                                                                                 \u001b[34mâ”ƒ\u001b[0m\n\u001b[34mâ”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›\u001b[0m\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "79315cdbf90341ed97d2c17b8f0b7051": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
