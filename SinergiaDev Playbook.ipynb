{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPWEhGa0m2SU"
      },
      "source": [
        "**Sinergia Dev** playbook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Rg0qWBno1O4"
      },
      "source": [
        "# Openai Responses API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUiDqKuHo8xO"
      },
      "source": [
        "- python install requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UYfa5CfsoicL",
        "outputId": "15c7ca6c-fae1-4c12-a5df-603a3d0706b1"
      },
      "outputs": [],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiDdYIHeb--6",
        "outputId": "297b111a-31c7-4e0e-9ed6-c7f6599a55aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter API key for OpenAI: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        }
      ],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "# set env for openai key:\n",
        "\n",
        "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "P9h03_IfpSGE",
        "outputId": "0b1c90be-371f-4987-c584-6fb6397196d4"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "# Generate text from a simple prompt\n",
        "\n",
        "## ChatGPT LLM single call\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\"Escribe un cuento de buenas noches en una sola oraciÃ³n sobre un unicornio.\"\n",
        ")\n",
        "\n",
        "## print response output text\n",
        "print(\"response.output_text:\\n\")\n",
        "print(response.output_text)\n",
        "\n",
        "## debug full response object\n",
        "print(\"response object:\\n\")\n",
        "pprint.pprint(response.model_dump())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "HvzCmUkerDzi",
        "outputId": "b9caa0ff-c31c-4d09-a26e-90d3d89c22d5"
      },
      "outputs": [],
      "source": [
        "# Generate text with instructions\n",
        "\n",
        "## ChatGPT LLM single call\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o\",\n",
        "    instructions=\"Your goals is to translate to english every user input\",\n",
        "    input=\"Escribe un cuento de buenas noches en una sola oraciÃ³n sobre un unicornio.\",\n",
        ")\n",
        "\n",
        "## print response output text\n",
        "print(\"response.output_text:\\n\")\n",
        "print(response.output_text)\n",
        "\n",
        "## debug full response object\n",
        "print(\"response object:\\n\")\n",
        "pprint.pprint(response.model_dump())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRIbvrqPxWJh",
        "outputId": "50cc73cb-ca46-4ee0-9354-0fa742b0f7cd"
      },
      "outputs": [],
      "source": [
        "# Generate text with messages using different roles\n",
        "\n",
        "## ChatGPT LLM with message history style (it will preserve instructions on history)\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=[\n",
        "        {\n",
        "            \"role\": \"developer\",\n",
        "            \"content\": \"Your goals is to translate to spanish every user input\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Are semicolons optional in JavaScript?\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "## print response output text\n",
        "print(\"response.output_text:\\n\")\n",
        "print(response.output_text)\n",
        "\n",
        "## debug full response object\n",
        "print(\"response object:\\n\")\n",
        "pprint.pprint(response.model_dump())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jst96GmlyzTx"
      },
      "source": [
        "# Structured Outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiwAXtLSyxVs",
        "outputId": "c759f787-b0ff-422b-c021-72610b8cfb37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'name': 'SinergIA-Dev', 'date': '2023-03-25T15:00:00', 'participants': ['Matias', 'Jony']}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# structured output models support by:\n",
        "\n",
        "# gpt-4.5-preview-2025-02-27 and later\n",
        "# o3-mini-2025-1-31 and later\n",
        "# o1-2024-12-17 and later\n",
        "# gpt-4o-mini-2024-07-18 and later\n",
        "# gpt-4o-2024-08-06 and later\n",
        "\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o-2024-08-06\",\n",
        "    input=[\n",
        "        {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Matias and Jony are going to SinergIA-Dev on 25 Friday, march at 15hs.\"}\n",
        "    ],\n",
        "    text={\n",
        "        \"format\": {\n",
        "            \"type\": \"json_schema\",\n",
        "            \"name\": \"calendar_event\",\n",
        "            \"schema\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"name\": {\n",
        "                        \"type\": \"string\"\n",
        "                    },\n",
        "                    \"date\": {\n",
        "                        \"type\": \"string\"\n",
        "                    },\n",
        "                    \"participants\": {\n",
        "                        \"type\": \"array\",\n",
        "                        \"items\": {\n",
        "                            \"type\": \"string\"\n",
        "                        }\n",
        "                    },\n",
        "                },\n",
        "                \"required\": [\"name\", \"date\", \"participants\"],\n",
        "                \"additionalProperties\": False\n",
        "            },\n",
        "            \"strict\": True\n",
        "        }\n",
        "    }\n",
        ")\n",
        "\n",
        "event = json.loads(response.output_text)\n",
        "\n",
        "print(event)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwKcmCPH0aqd",
        "outputId": "49294c06-48b6-4c52-a2fd-96aeb4782ba0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'final_answer': 'x = -\\\\frac{15}{4}',\n",
            " 'steps': [{'explanation': \"Start by isolating the term with the variable 'x'. \"\n",
            "                           'We need to move the constant term on the left side '\n",
            "                           'to the right side. To do this, subtract 7 from '\n",
            "                           'both sides of the equation.',\n",
            "            'output': '8x + 7 - 7 = -23 - 7'},\n",
            "           {'explanation': 'This simplifies to:', 'output': '8x = -30'},\n",
            "           {'explanation': \"Next, solve for 'x' by dividing both sides of the \"\n",
            "                           'equation by 8.',\n",
            "            'output': '\\\\( x = \\\\frac{-30}{8} \\\\)'},\n",
            "           {'explanation': 'Simplify the fraction by dividing the numerator '\n",
            "                           'and the denominator by their greatest common '\n",
            "                           'divisor, which is 2.',\n",
            "            'output': '\\\\( x = \\\\frac{-15}{4} \\\\)'},\n",
            "           {'explanation': 'Thus, the solution to the equation is:',\n",
            "            'output': 'x = -\\\\frac{15}{4}'}]}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import pprint\n",
        "\n",
        "# Structured Outputs for chain-of-thought math tutoring\n",
        "\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o-2024-08-06\",\n",
        "    input=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful math tutor. Guide the user through the solution step by step.\"},\n",
        "        {\"role\": \"user\", \"content\": \"how can I solve 8x + 7 = -23\"}\n",
        "    ],\n",
        "    text={\n",
        "        \"format\": {\n",
        "            \"type\": \"json_schema\",\n",
        "            \"name\": \"math_reasoning\",\n",
        "            \"schema\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"steps\": {\n",
        "                        \"type\": \"array\",\n",
        "                        \"items\": {\n",
        "                            \"type\": \"object\",\n",
        "                            \"properties\": {\n",
        "                                \"explanation\": { \"type\": \"string\" },\n",
        "                                \"output\": { \"type\": \"string\" }\n",
        "                            },\n",
        "                            \"required\": [\"explanation\", \"output\"],\n",
        "                            \"additionalProperties\": False\n",
        "                        }\n",
        "                    },\n",
        "                    \"final_answer\": { \"type\": \"string\" }\n",
        "                },\n",
        "                \"required\": [\"steps\", \"final_answer\"],\n",
        "                \"additionalProperties\": False\n",
        "            },\n",
        "            \"strict\": True\n",
        "        }\n",
        "    }\n",
        ")\n",
        "\n",
        "math_reasoning = json.loads(response.output_text)\n",
        "pprint.pprint(math_reasoning)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nYLXmhOCbYKy",
        "outputId": "dc976272-1500-4f14-bf56-c439b2c159b6"
      },
      "outputs": [],
      "source": [
        "# https://python.langchain.com/docs/concepts/prompt_templates/\n",
        "# install langchain\n",
        "\n",
        "!pip install langchain\n",
        "!pip install -qU \"langchain[openai]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6-Cj8aGbj-A",
        "outputId": "a87c3fa6-67c2-418c-e566-5d28768dbda5"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "# define model to use\n",
        "model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
        "\n",
        "# message preparation:\n",
        "\n",
        "## using history messages:\n",
        "messages = [\n",
        "    SystemMessage(\"Translate the following from English into Spanish\"),\n",
        "    HumanMessage(\"hi! Im a developer trying to learn AI\"),\n",
        "]\n",
        "\n",
        "# LLM call\n",
        "\n",
        "## invoke chat completion\n",
        "response = model.invoke(messages)\n",
        "\n",
        "# print response text\n",
        "print(\"response.content:\\n\")\n",
        "print(response.content + \"\\n\")\n",
        "print(\"response object:\\n\")\n",
        "pprint.pprint(response.model_dump())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hakqOW1PjREl"
      },
      "outputs": [],
      "source": [
        "# example for a dynamic template completion\n",
        "\n",
        "## using template with variables\n",
        "system_template = \"Translate the following from English into {language}\" # variable on template interpolated with {var_name}\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
        ")\n",
        "\n",
        "prompt = prompt_template.invoke({\"language\": \"Italian\", \"text\": \"hi! Please take the recommended actions to update your configuration\"})\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6TUcu9DcXnD",
        "outputId": "ff9d7c3a-d09b-46fa-88f2-0bac1f0d22c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Why do programmers prefer dark mode?  \n",
            "\n",
            "Because light attracts bugs!\n"
          ]
        }
      ],
      "source": [
        "template_prompt = ChatPromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
        "\n",
        "chain = template_prompt | model\n",
        "response1 = chain.invoke({\"topic\": \"programming\"})\n",
        "print(response1.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gtIdQ1hfQ6b",
        "outputId": "91712a1c-60eb-43c9-ee29-0040cf84cd11"
      },
      "outputs": [],
      "source": [
        "import pprint\n",
        "\n",
        "pprint.pprint(response1.model_dump())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9EqlFSZ7KwI"
      },
      "source": [
        "# Composed LLM (chaining)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzkqXIv_7Wnb"
      },
      "source": [
        "- pedir un boceto de algo al llm\n",
        "- pedir una critica del boceto\n",
        "- pedir algo al llm incluyendo el boceto y la critica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iRx5SeK7Zju"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ze4WZy6BXAm"
      },
      "source": [
        "# Agents: Human in the loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSGMBhKv58lr"
      },
      "outputs": [],
      "source": [
        "# https://github.com/agno-agi/agno"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "eMRAe3Rt7bU2",
        "outputId": "fc584537-d8f0-4d17-88f0-012e6edecc3f"
      },
      "outputs": [],
      "source": [
        "!pip install httpx rich agno"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537,
          "referenced_widgets": [
            "347559df903540dd8ff69da3e85ec63b",
            "79315cdbf90341ed97d2c17b8f0b7051"
          ]
        },
        "collapsed": true,
        "id": "W6lpRf05AiX7",
        "outputId": "48bfd5e0-1bb0-42e2-e3c7-cbaee7190e0d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "347559df903540dd8ff69da3e85ec63b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "About to run <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">get_top_hackernews_stories</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "About to run \u001b[1;34mget_top_hackernews_stories\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Do you want to continue? <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">[y/n]</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">(y)</span>: </pre>\n"
            ],
            "text/plain": [
              "Do you want to continue? \u001b[1;35m[y/n]\u001b[0m \u001b[1;36m(y)\u001b[0m: "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\"\"\"ğŸ¤ Human-in-the-Loop: Adding User Confirmation to Tool Calls\n",
        "\n",
        "This example shows how to implement human-in-the-loop functionality in your Agno tools.\n",
        "It shows how to:\n",
        "- Add pre-hooks to tools for user confirmation\n",
        "- Handle user input during tool execution\n",
        "- Gracefully cancel operations based on user choice\n",
        "\n",
        "Some practical applications:\n",
        "- Confirming sensitive operations before execution\n",
        "- Reviewing API calls before they're made\n",
        "- Validating data transformations\n",
        "- Approving automated actions in critical systems\n",
        "\n",
        "Run `pip install openai httpx rich agno` to install dependencies.\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "from textwrap import dedent\n",
        "from typing import Iterator\n",
        "\n",
        "import httpx\n",
        "from agno.agent import Agent\n",
        "from agno.exceptions import StopAgentRun\n",
        "from agno.tools import FunctionCall, tool\n",
        "from rich.console import Console\n",
        "from rich.pretty import pprint\n",
        "from rich.prompt import Prompt\n",
        "\n",
        "# This is the console instance used by the print_response method\n",
        "# We can use this to stop and restart the live display and ask for user confirmation\n",
        "console = Console()\n",
        "\n",
        "\n",
        "def pre_hook(fc: FunctionCall):\n",
        "    # Get the live display instance from the console\n",
        "    live = console._live\n",
        "\n",
        "    # Stop the live display temporarily so we can ask for user confirmation\n",
        "    live.stop()  # type: ignore\n",
        "\n",
        "    # Ask for confirmation\n",
        "    console.print(f\"\\nAbout to run [bold blue]{fc.function.name}[/]\")\n",
        "    message = (\n",
        "        Prompt.ask(\"Do you want to continue?\", choices=[\"y\", \"n\"], default=\"y\")\n",
        "        .strip()\n",
        "        .lower()\n",
        "    )\n",
        "\n",
        "    # Restart the live display\n",
        "    live.start()  # type: ignore\n",
        "\n",
        "    # If the user does not want to continue, raise a StopExecution exception\n",
        "    if message != \"y\":\n",
        "        raise StopAgentRun(\n",
        "            \"Tool call cancelled by user\",\n",
        "            agent_message=\"Stopping execution as permission was not granted.\",\n",
        "        )\n",
        "\n",
        "\n",
        "@tool(pre_hook=pre_hook)\n",
        "def get_top_hackernews_stories(num_stories: int) -> Iterator[str]:\n",
        "    \"\"\"Fetch top stories from Hacker News after user confirmation.\n",
        "\n",
        "    Args:\n",
        "        num_stories (int): Number of stories to retrieve\n",
        "\n",
        "    Returns:\n",
        "        str: JSON string containing story details\n",
        "    \"\"\"\n",
        "    # Fetch top story IDs\n",
        "    response = httpx.get(\"https://hacker-news.firebaseio.com/v0/topstories.json\")\n",
        "    story_ids = response.json()\n",
        "\n",
        "    # Yield story details\n",
        "    for story_id in story_ids[:num_stories]:\n",
        "        story_response = httpx.get(\n",
        "            f\"https://hacker-news.firebaseio.com/v0/item/{story_id}.json\"\n",
        "        )\n",
        "        story = story_response.json()\n",
        "        if \"text\" in story:\n",
        "            story.pop(\"text\", None)\n",
        "        yield json.dumps(story)\n",
        "\n",
        "\n",
        "# Initialize the agent with a tech-savvy personality and clear instructions\n",
        "agent = Agent(\n",
        "    description=\"A Tech News Assistant that fetches and summarizes Hacker News stories\",\n",
        "    instructions=dedent(\"\"\"\\\n",
        "        You are an enthusiastic Tech Reporter\n",
        "\n",
        "        Your responsibilities:\n",
        "        - Present Hacker News stories in an engaging and informative way\n",
        "        - Provide clear summaries of the information you gather\n",
        "\n",
        "        Style guide:\n",
        "        - Use emoji to make your responses more engaging\n",
        "        - Keep your summaries concise but informative\n",
        "        - End with a friendly tech-themed sign-off\\\n",
        "    \"\"\"),\n",
        "    tools=[get_top_hackernews_stories],\n",
        "    show_tool_calls=True,\n",
        "    markdown=True,\n",
        ")\n",
        "\n",
        "# Example questions to try:\n",
        "# - \"What are the top 3 HN stories right now?\"\n",
        "# - \"Show me the most recent story from Hacker News\"\n",
        "# - \"Get the top 5 stories (you can try accepting and declining the confirmation)\"\n",
        "agent.print_response(\n",
        "    \"Show me a list of title from top 5 most recent story from Hacker News\", stream=True, console=console\n",
        ")\n",
        "\n",
        "# View all messages\n",
        "# pprint(agent.run_response.messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH3MRILz7OBs"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WO2VNtBAv3rw"
      },
      "source": [
        "# Memory w/mem0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwBuIBKh5y3V"
      },
      "outputs": [],
      "source": [
        "# https://github.com/mem0ai/mem0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jN9IF8aR7gMq"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QhEgL0oov_rM",
        "outputId": "a2c31c7a-510c-49e6-a8fd-258c1ac4f2a0"
      },
      "outputs": [],
      "source": [
        "!pip install mem0ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nf5KVXmzwBAI",
        "outputId": "a3b1001b-64f5-4573-833e-0be74791f6be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chat with AI (type 'exit' to quit)\n",
            "You: hola me llamo Matias y tengo 39 aÃ±os\n",
            "AI: Hola MatÃ­as, Â¡es un placer conocerte! Â¿En quÃ© puedo ayudarte hoy?\n",
            "You: uh perdon creo que te dije mal mi edad\n",
            "AI: No hay problema, MatÃ­as. Â¿CuÃ¡l es tu edad correcta?\n",
            "You: que edad te dije?\n",
            "AI: Me dijiste que tienes 39 aÃ±os.\n",
            "You: tengo 40\n",
            "AI: Â¡Feliz cumpleaÃ±os, MatÃ­as! Ahora tienes 40 aÃ±os. Â¿Hay algo especial que te gustarÃ­a hacer para celebrar este nuevo aÃ±o?\n",
            "You: exit\n",
            "Goodbye!\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "from mem0 import Memory\n",
        "\n",
        "openai_client = OpenAI()\n",
        "memory = Memory()\n",
        "\n",
        "def chat_with_memories(message: str, user_id: str = \"default_user\") -> str:\n",
        "    # Retrieve relevant memories\n",
        "    relevant_memories = memory.search(query=message, user_id=user_id, limit=3)\n",
        "    memories_str = \"\\n\".join(f\"- {entry['memory']}\" for entry in relevant_memories[\"results\"])\n",
        "\n",
        "    # Generate Assistant response\n",
        "    system_prompt = f\"You are a helpful AI. Answer the question based on query and memories.\\nUser Memories:\\n{memories_str}\"\n",
        "    messages = [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": message}]\n",
        "    # Completion API\n",
        "    response = openai_client.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
        "    assistant_response = response.choices[0].message.content\n",
        "\n",
        "    # Create new memories from the conversation\n",
        "    messages.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
        "    memory.add(messages, user_id=user_id)\n",
        "\n",
        "    return assistant_response\n",
        "\n",
        "def main():\n",
        "    print(\"Chat with AI (type 'exit' to quit)\")\n",
        "    while True:\n",
        "        user_input = input(\"You: \").strip()\n",
        "        if user_input.lower() == 'exit':\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "        print(f\"AI: {chat_with_memories(user_input)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "0_wx1b6icjRC",
        "R9EqlFSZ7KwI",
        "1ze4WZy6BXAm",
        "WO2VNtBAv3rw"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "347559df903540dd8ff69da3e85ec63b": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_79315cdbf90341ed97d2c17b8f0b7051",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">â–°â–°â–°â–°â–±â–±â–±</span> Thinking...\n<span style=\"color: #008080; text-decoration-color: #008080\">â”â” Message â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“</span>\n<span style=\"color: #008080; text-decoration-color: #008080\">â”ƒ</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">â”ƒ</span>\n<span style=\"color: #008080; text-decoration-color: #008080\">â”ƒ</span> <span style=\"color: #008000; text-decoration-color: #008000\">Show me a list of title from top 5 most recent story from Hacker News</span>                                           <span style=\"color: #008080; text-decoration-color: #008080\">â”ƒ</span>\n<span style=\"color: #008080; text-decoration-color: #008080\">â”ƒ</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">â”ƒ</span>\n<span style=\"color: #008080; text-decoration-color: #008080\">â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›</span>\n<span style=\"color: #808000; text-decoration-color: #808000\">â”â” Tool Calls â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“</span>\n<span style=\"color: #808000; text-decoration-color: #808000\">â”ƒ</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”ƒ</span>\n<span style=\"color: #808000; text-decoration-color: #808000\">â”ƒ</span> â€¢ get_top_hackernews_stories(num_stories=5)                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">â”ƒ</span>\n<span style=\"color: #808000; text-decoration-color: #808000\">â”ƒ</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”ƒ</span>\n<span style=\"color: #808000; text-decoration-color: #808000\">â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">â”â” Response (7.3s) â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span> Here are the top 5 most recent stories from Hacker News:                                                        <span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">OpenAI adds MCP support to Agents SDK</span>                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span><a href=\"https://openai.github.io/openai-agents-python/mcp/\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; text-decoration: underline\">Read more</span></a>                                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">Debian bookworm live images now reproducible</span>                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span><a href=\"https://lwn.net/Articles/1015402/\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; text-decoration: underline\">Read more</span></a>                                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 3 </span><span style=\"font-weight: bold\">The Mysterious Flow of Fluid in the Brain</span>                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span><a href=\"https://www.quantamagazine.org/the-mysterious-flow-of-fluid-in-the-brain-20250326/\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; text-decoration: underline\">Read more</span></a>                                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 4 </span><span style=\"font-weight: bold\">A love letter to the CSV format</span>                                                                              <span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span><a href=\"https://github.com/medialab/xan/blob/master/docs/LOVE_LETTER.md\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; text-decoration: underline\">Read more</span></a>                                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 5 </span><span style=\"font-weight: bold\">Building a Linux Container Runtime from Scratch</span>                                                              <span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span><a href=\"https://edera.dev/stories/styrolite\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; text-decoration: underline\">Read more</span></a>                                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span> Stay tuned for more tech tidbits! ğŸ–¥ï¸ğŸ”                                                                           <span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">â”ƒ</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›</span>\n</pre>\n",
                  "text/plain": "\u001b[32mâ–°â–°â–°â–°â–±â–±â–±\u001b[0m Thinking...\n\u001b[36mâ”â”\u001b[0m\u001b[36m Message \u001b[0m\u001b[36mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[36mâ”â”“\u001b[0m\n\u001b[36mâ”ƒ\u001b[0m                                                                                                                 \u001b[36mâ”ƒ\u001b[0m\n\u001b[36mâ”ƒ\u001b[0m \u001b[32mShow me a list of title from top 5 most recent story from Hacker News\u001b[0m                                           \u001b[36mâ”ƒ\u001b[0m\n\u001b[36mâ”ƒ\u001b[0m                                                                                                                 \u001b[36mâ”ƒ\u001b[0m\n\u001b[36mâ”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›\u001b[0m\n\u001b[33mâ”â”\u001b[0m\u001b[33m Tool Calls \u001b[0m\u001b[33mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[33mâ”â”“\u001b[0m\n\u001b[33mâ”ƒ\u001b[0m                                                                                                                 \u001b[33mâ”ƒ\u001b[0m\n\u001b[33mâ”ƒ\u001b[0m â€¢ get_top_hackernews_stories(num_stories=5)                                                                     \u001b[33mâ”ƒ\u001b[0m\n\u001b[33mâ”ƒ\u001b[0m                                                                                                                 \u001b[33mâ”ƒ\u001b[0m\n\u001b[33mâ”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›\u001b[0m\n\u001b[34mâ”â”\u001b[0m\u001b[34m Response (7.3s) \u001b[0m\u001b[34mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[34mâ”â”“\u001b[0m\n\u001b[34mâ”ƒ\u001b[0m                                                                                                                 \u001b[34mâ”ƒ\u001b[0m\n\u001b[34mâ”ƒ\u001b[0m Here are the top 5 most recent stories from Hacker News:                                                        \u001b[34mâ”ƒ\u001b[0m\n\u001b[34mâ”ƒ\u001b[0m                                                                                                                 \u001b[34mâ”ƒ\u001b[0m\n\u001b[34mâ”ƒ\u001b[0m \u001b[1;33m 1 \u001b[0m\u001b[1mOpenAI adds MCP support to Agents SDK\u001b[0m                                                                        \u001b[34mâ”ƒ\u001b[0m\n\u001b[34mâ”ƒ\u001b[0m \u001b[1;33m   \u001b[0m\u001b]8;id=501521;https://openai.github.io/openai-agents-python/mcp/\u001b\\\u001b[4;34mRead more\u001b[0m\u001b]8;;\u001b\\                                                                                                    \u001b[34mâ”ƒ\u001b[0m\n\u001b[34mâ”ƒ\u001b[0m \u001b[1;33m 2 \u001b[0m\u001b[1mDebian bookworm live images now reproducible\u001b[0m                                                                 \u001b[34mâ”ƒ\u001b[0m\n\u001b[34mâ”ƒ\u001b[0m \u001b[1;33m   \u001b[0m\u001b]8;id=698136;https://lwn.net/Articles/1015402/\u001b\\\u001b[4;34mRead more\u001b[0m\u001b]8;;\u001b\\                                                                                                    \u001b[34mâ”ƒ\u001b[0m\n\u001b[34mâ”ƒ\u001b[0m \u001b[1;33m 3 \u001b[0m\u001b[1mThe Mysterious Flow of Fluid in the Brain\u001b[0m                                                                    \u001b[34mâ”ƒ\u001b[0m\n\u001b[34mâ”ƒ\u001b[0m \u001b[1;33m   \u001b[0m\u001b]8;id=599249;https://www.quantamagazine.org/the-mysterious-flow-of-fluid-in-the-brain-20250326/\u001b\\\u001b[4;34mRead more\u001b[0m\u001b]8;;\u001b\\                                                                                                    \u001b[34mâ”ƒ\u001b[0m\n\u001b[34mâ”ƒ\u001b[0m \u001b[1;33m 4 \u001b[0m\u001b[1mA love letter to the CSV format\u001b[0m                                                                              \u001b[34mâ”ƒ\u001b[0m\n\u001b[34mâ”ƒ\u001b[0m \u001b[1;33m   \u001b[0m\u001b]8;id=801033;https://github.com/medialab/xan/blob/master/docs/LOVE_LETTER.md\u001b\\\u001b[4;34mRead more\u001b[0m\u001b]8;;\u001b\\                                                                                                    \u001b[34mâ”ƒ\u001b[0m\n\u001b[34mâ”ƒ\u001b[0m \u001b[1;33m 5 \u001b[0m\u001b[1mBuilding a Linux Container Runtime from Scratch\u001b[0m                                                              \u001b[34mâ”ƒ\u001b[0m\n\u001b[34mâ”ƒ\u001b[0m \u001b[1;33m   \u001b[0m\u001b]8;id=180920;https://edera.dev/stories/styrolite\u001b\\\u001b[4;34mRead more\u001b[0m\u001b]8;;\u001b\\                                                                                                    \u001b[34mâ”ƒ\u001b[0m\n\u001b[34mâ”ƒ\u001b[0m                                                                                                                 \u001b[34mâ”ƒ\u001b[0m\n\u001b[34mâ”ƒ\u001b[0m Stay tuned for more tech tidbits! ğŸ–¥ï¸ğŸ”                                                                           \u001b[34mâ”ƒ\u001b[0m\n\u001b[34mâ”ƒ\u001b[0m                                                                                                                 \u001b[34mâ”ƒ\u001b[0m\n\u001b[34mâ”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›\u001b[0m\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "79315cdbf90341ed97d2c17b8f0b7051": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
