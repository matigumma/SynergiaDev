{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPWEhGa0m2SU"
      },
      "source": [
        "**Sinergia Dev** playbook base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Rg0qWBno1O4"
      },
      "source": [
        "# Openai Responses API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUiDqKuHo8xO"
      },
      "source": [
        "- python install requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UYfa5CfsoicL",
        "outputId": "15c7ca6c-fae1-4c12-a5df-603a3d0706b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in ./.venv/lib/python3.11/site-packages (1.76.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.11/site-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.11/site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.11/site-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.11/site-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in ./.venv/lib/python3.11/site-packages (from openai) (2.11.3)\n",
            "Requirement already satisfied: sniffio in ./.venv/lib/python3.11/site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.11/site-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in ./.venv/lib/python3.11/site-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiDdYIHeb--6",
        "outputId": "297b111a-31c7-4e0e-9ed6-c7f6599a55aa"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "# set env for openai key:\n",
        "\n",
        "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "P9h03_IfpSGE",
        "outputId": "0b1c90be-371f-4987-c584-6fb6397196d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "response.output_text:\n",
            "\n",
            "Una noche estrellada, un unicornio llamado Luno iluminó el bosque con su cuerno brillante mientras danzaba entre los sueños de los niños, asegurando que cada uno despertara con una sonrisa en el corazón.\n",
            "response object:\n",
            "\n",
            "{'created_at': 1745446012.0,\n",
            " 'error': None,\n",
            " 'id': 'resp_6809647cd4248192af35ade638330f1807e15694723ac3b9',\n",
            " 'incomplete_details': None,\n",
            " 'instructions': None,\n",
            " 'max_output_tokens': None,\n",
            " 'metadata': {},\n",
            " 'model': 'gpt-4o-mini-2024-07-18',\n",
            " 'object': 'response',\n",
            " 'output': [{'content': [{'annotations': [],\n",
            "                          'text': 'Una noche estrellada, un unicornio llamado '\n",
            "                                  'Luno iluminó el bosque con su cuerno '\n",
            "                                  'brillante mientras danzaba entre los sueños '\n",
            "                                  'de los niños, asegurando que cada uno '\n",
            "                                  'despertara con una sonrisa en el corazón.',\n",
            "                          'type': 'output_text'}],\n",
            "             'id': 'msg_6809647d545481928a7b478c14ddbc9707e15694723ac3b9',\n",
            "             'role': 'assistant',\n",
            "             'status': 'completed',\n",
            "             'type': 'message'}],\n",
            " 'parallel_tool_calls': True,\n",
            " 'previous_response_id': None,\n",
            " 'reasoning': {'effort': None, 'generate_summary': None, 'summary': None},\n",
            " 'service_tier': 'default',\n",
            " 'status': 'completed',\n",
            " 'store': True,\n",
            " 'temperature': 1.0,\n",
            " 'text': {'format': {'type': 'text'}},\n",
            " 'tool_choice': 'auto',\n",
            " 'tools': [],\n",
            " 'top_p': 1.0,\n",
            " 'truncation': 'disabled',\n",
            " 'usage': {'input_tokens': 23,\n",
            "           'input_tokens_details': {'cached_tokens': 0},\n",
            "           'output_tokens': 47,\n",
            "           'output_tokens_details': {'reasoning_tokens': 0},\n",
            "           'total_tokens': 70},\n",
            " 'user': None}\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "import pprint\n",
        "client = OpenAI()\n",
        "\n",
        "# GENERA UN TEXTO EN BASE A UN PROMPT SIMPLE \n",
        "# NIVEL 1\n",
        "\n",
        "## ChatGPT LLM single call\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\"Escribe un cuento de buenas noches en una sola oración sobre un unicornio.\"\n",
        ")\n",
        "\n",
        "## print response output text\n",
        "print(\"response.output_text:\\n\")\n",
        "pprint.pprint(response.output_text)\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "## debug full response object\n",
        "print(\"response object:\\n\")\n",
        "pprint.pprint(response.model_dump())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "HvzCmUkerDzi",
        "outputId": "b9caa0ff-c31c-4d09-a26e-90d3d89c22d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "response.output_text:\n",
            "\n",
            "Write a one-sentence bedtime story about a unicorn.\n",
            "\n",
            "\n",
            "\n",
            "response object:\n",
            "\n",
            "{'created_at': 1745447673.0,\n",
            " 'error': None,\n",
            " 'id': 'resp_68096af9513c81929ea75ee392a952750ba1855e4c491965',\n",
            " 'incomplete_details': None,\n",
            " 'instructions': 'You are an english translator. User will write a prompt. '\n",
            "                 'Your goals is to translate the user prompt',\n",
            " 'max_output_tokens': None,\n",
            " 'metadata': {},\n",
            " 'model': 'gpt-4o-2024-08-06',\n",
            " 'object': 'response',\n",
            " 'output': [{'content': [{'annotations': [],\n",
            "                          'text': 'Write a one-sentence bedtime story about a '\n",
            "                                  'unicorn.',\n",
            "                          'type': 'output_text'}],\n",
            "             'id': 'msg_68096af9d09881928f3adc91d67b24190ba1855e4c491965',\n",
            "             'role': 'assistant',\n",
            "             'status': 'completed',\n",
            "             'type': 'message'}],\n",
            " 'parallel_tool_calls': True,\n",
            " 'previous_response_id': None,\n",
            " 'reasoning': {'effort': None, 'generate_summary': None, 'summary': None},\n",
            " 'service_tier': 'default',\n",
            " 'status': 'completed',\n",
            " 'store': True,\n",
            " 'temperature': 1.0,\n",
            " 'text': {'format': {'type': 'text'}},\n",
            " 'tool_choice': 'auto',\n",
            " 'tools': [],\n",
            " 'top_p': 1.0,\n",
            " 'truncation': 'disabled',\n",
            " 'usage': {'input_tokens': 47,\n",
            "           'input_tokens_details': {'cached_tokens': 0},\n",
            "           'output_tokens': 12,\n",
            "           'output_tokens_details': {'reasoning_tokens': 0},\n",
            "           'total_tokens': 59},\n",
            " 'user': None}\n"
          ]
        }
      ],
      "source": [
        "# GENERA UN TEXTO CON UN PROMPT SIMPLE PERO AGREGANDOLE VARIABLES ESTATICAS (INSTRUCCIONES)\n",
        "# NIVEL 2\n",
        "\n",
        "## ChatGPT LLM single call\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o\", # \"gpt-4o-mini\" no entiende las instrucciones...\n",
        "    instructions=\"You are an english translator. User will write a prompt. Your goals is to translate the user prompt\", # estas son variables estaticas tambien\n",
        "    input=\"Escribe un cuento de buenas noches en una sola oración sobre un unicornio.\",\n",
        ")\n",
        "\n",
        "## print response output text\n",
        "print(\"response.output_text:\\n\")\n",
        "pprint.pprint(response.output_text)\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "## debug full response object\n",
        "print(\"response object:\\n\")\n",
        "pprint.pprint(response.model_dump())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRIbvrqPxWJh",
        "outputId": "50cc73cb-ca46-4ee0-9354-0fa742b0f7cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "¡Claro! Aquí tienes uno:\n",
            "\n",
            "¿Por qué los programadores prefieren el café al té?\n",
            "\n",
            "Porque el té tiene demasiados \"bugs\". ☕🐛\n",
            "\n",
            "Espero que te haya sacado una sonrisa. ¡Si quieres otro, avísame!\n",
            "\n",
            "\n",
            "\n",
            "¡Claro! El chiste juega con dos conceptos:\n",
            "\n",
            "1. **Café vs. Té**: Es un estereotipo en la cultura de los programadores que muchos prefieren el café, especialmente por su cafeína, que los ayuda a mantenerse despiertos durante largas horas de codificación.\n",
            "\n",
            "2. **Bugs**: En programación, un \"bug\" es un error o falla en el código. La broma implica que el té \"tiene demasiados bugs\", insinuando que podría ser menos efectivo o más problemático, como un programa lleno de errores.\n",
            "\n",
            "La clave está en la conexión entre el término técnico (\"bugs\") y la idea de que el té es menos deseable. Es un juego de palabras que combina lo cotidiano con el mundo de la programación, lo que suele generar una sonrisa entre quienes están familiarizados con esos conceptos. ¡Espero que esto aclare la broma!\n",
            "\n",
            "\n",
            "\n",
            "response object:\n",
            "\n",
            "{'created_at': 1745448939.0,\n",
            " 'error': None,\n",
            " 'id': 'resp_68096febada08192abd41d34457a54c904cd980b77862b79',\n",
            " 'incomplete_details': None,\n",
            " 'instructions': None,\n",
            " 'max_output_tokens': None,\n",
            " 'metadata': {},\n",
            " 'model': 'gpt-4o-mini-2024-07-18',\n",
            " 'object': 'response',\n",
            " 'output': [{'content': [{'annotations': [],\n",
            "                          'text': '¡Claro! Aquí tienes uno:\\n'\n",
            "                                  '\\n'\n",
            "                                  '¿Por qué los programadores prefieren el '\n",
            "                                  'café al té?\\n'\n",
            "                                  '\\n'\n",
            "                                  'Porque el té tiene demasiados \"bugs\". ☕🐛\\n'\n",
            "                                  '\\n'\n",
            "                                  'Espero que te haya sacado una sonrisa. ¡Si '\n",
            "                                  'quieres otro, avísame!',\n",
            "                          'type': 'output_text'}],\n",
            "             'id': 'msg_68096febff448192830cebd25eaa1a4604cd980b77862b79',\n",
            "             'role': 'assistant',\n",
            "             'status': 'completed',\n",
            "             'type': 'message'}],\n",
            " 'parallel_tool_calls': True,\n",
            " 'previous_response_id': None,\n",
            " 'reasoning': {'effort': None, 'generate_summary': None, 'summary': None},\n",
            " 'service_tier': 'default',\n",
            " 'status': 'completed',\n",
            " 'store': True,\n",
            " 'temperature': 1.0,\n",
            " 'text': {'format': {'type': 'text'}},\n",
            " 'tool_choice': 'auto',\n",
            " 'tools': [],\n",
            " 'top_p': 1.0,\n",
            " 'truncation': 'disabled',\n",
            " 'usage': {'input_tokens': 15,\n",
            "           'input_tokens_details': {'cached_tokens': 0},\n",
            "           'output_tokens': 52,\n",
            "           'output_tokens_details': {'reasoning_tokens': 0},\n",
            "           'total_tokens': 67},\n",
            " 'user': None}\n",
            "\n",
            "\n",
            "\n",
            "second_response object:\n",
            "\n",
            "{'created_at': 1745448941.0,\n",
            " 'error': None,\n",
            " 'id': 'resp_68096fed2e008192819641bd69e8fa8c04cd980b77862b79',\n",
            " 'incomplete_details': None,\n",
            " 'instructions': None,\n",
            " 'max_output_tokens': None,\n",
            " 'metadata': {},\n",
            " 'model': 'gpt-4o-mini-2024-07-18',\n",
            " 'object': 'response',\n",
            " 'output': [{'content': [{'annotations': [],\n",
            "                          'text': '¡Claro! El chiste juega con dos conceptos:\\n'\n",
            "                                  '\\n'\n",
            "                                  '1. **Café vs. Té**: Es un estereotipo en la '\n",
            "                                  'cultura de los programadores que muchos '\n",
            "                                  'prefieren el café, especialmente por su '\n",
            "                                  'cafeína, que los ayuda a mantenerse '\n",
            "                                  'despiertos durante largas horas de '\n",
            "                                  'codificación.\\n'\n",
            "                                  '\\n'\n",
            "                                  '2. **Bugs**: En programación, un \"bug\" es '\n",
            "                                  'un error o falla en el código. La broma '\n",
            "                                  'implica que el té \"tiene demasiados bugs\", '\n",
            "                                  'insinuando que podría ser menos efectivo o '\n",
            "                                  'más problemático, como un programa lleno de '\n",
            "                                  'errores.\\n'\n",
            "                                  '\\n'\n",
            "                                  'La clave está en la conexión entre el '\n",
            "                                  'término técnico (\"bugs\") y la idea de que '\n",
            "                                  'el té es menos deseable. Es un juego de '\n",
            "                                  'palabras que combina lo cotidiano con el '\n",
            "                                  'mundo de la programación, lo que suele '\n",
            "                                  'generar una sonrisa entre quienes están '\n",
            "                                  'familiarizados con esos conceptos. ¡Espero '\n",
            "                                  'que esto aclare la broma!',\n",
            "                          'type': 'output_text'}],\n",
            "             'id': 'msg_68096fed80848192b1d55a2f4db1732204cd980b77862b79',\n",
            "             'role': 'assistant',\n",
            "             'status': 'completed',\n",
            "             'type': 'message'}],\n",
            " 'parallel_tool_calls': True,\n",
            " 'previous_response_id': 'resp_68096febada08192abd41d34457a54c904cd980b77862b79',\n",
            " 'reasoning': {'effort': None, 'generate_summary': None, 'summary': None},\n",
            " 'service_tier': 'default',\n",
            " 'status': 'completed',\n",
            " 'store': True,\n",
            " 'temperature': 1.0,\n",
            " 'text': {'format': {'type': 'text'}},\n",
            " 'tool_choice': 'auto',\n",
            " 'tools': [],\n",
            " 'top_p': 1.0,\n",
            " 'truncation': 'disabled',\n",
            " 'usage': {'input_tokens': 82,\n",
            "           'input_tokens_details': {'cached_tokens': 0},\n",
            "           'output_tokens': 183,\n",
            "           'output_tokens_details': {'reasoning_tokens': 0},\n",
            "           'total_tokens': 265},\n",
            " 'user': None}\n"
          ]
        }
      ],
      "source": [
        "# GENERA UN TEXTO CON UN history messages USANDO DIFERENTES ROLES (developer, user, assistant)\n",
        "# MANEJO DEL CONTEXTO...\n",
        "\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\"contame un chiste de programadores\",\n",
        ")\n",
        "print(response.output_text)\n",
        "print(\"\\n\\n\")\n",
        "second_response = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    previous_response_id=response.id, # esta es la forma de persistir el puntero del historial entre llamadas\n",
        "    input=[{\"role\": \"user\", \"content\": \"explicame porque es gracioso.\"}],\n",
        ")\n",
        "print(second_response.output_text)\n",
        "\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "## debug full response object\n",
        "print(\"response object:\\n\")\n",
        "pprint.pprint(response.model_dump())\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "## debug full response object\n",
        "print(\"second_response object:\\n\")\n",
        "pprint.pprint(second_response.model_dump())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jst96GmlyzTx"
      },
      "source": [
        "# Structured Outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiwAXtLSyxVs",
        "outputId": "c759f787-b0ff-422b-c021-72610b8cfb37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'event_name': 'SinergIA-Dev', 'date': '24 April 2023', 'participants': ['Matias', 'Jony']}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# GENERA UN JSON EN BASE A UNA ESTRUCTURA json DADA\n",
        "# NIVEL 2\n",
        "\n",
        "# structured output models support by:\n",
        "\n",
        "# gpt-4.5-preview-2025-02-27 and later\n",
        "# o3-mini-2025-1-31 and later\n",
        "# o1-2024-12-17 and later\n",
        "# gpt-4o-mini-2024-07-18 and later\n",
        "# gpt-4o-2024-08-06 and later\n",
        "\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o-2024-08-06\",\n",
        "    input=[\n",
        "        {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Matias and Jony are going to SinergIA-Dev on 24 thursday, april at 15hs.\"}\n",
        "    ],\n",
        "    text={\n",
        "        \"format\": {\n",
        "            \"type\": \"json_schema\",\n",
        "            \"name\": \"calendar_event\",\n",
        "            \"schema\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"event_name\": {\n",
        "                        \"type\": \"string\"\n",
        "                    },\n",
        "                    \"date\": {\n",
        "                        \"type\": \"string\",\n",
        "                    },\n",
        "                    \"participants\": {\n",
        "                        \"type\": \"array\",\n",
        "                        \"items\": {\n",
        "                            \"type\": \"string\"\n",
        "                        }\n",
        "                    },\n",
        "                },\n",
        "                \"required\": [\"event_name\", \"date\", \"participants\"],\n",
        "                \"additionalProperties\": False\n",
        "            },\n",
        "            \"strict\": True\n",
        "        }\n",
        "    }\n",
        ")\n",
        "\n",
        "event = json.loads(response.output_text)\n",
        "\n",
        "pprint.pprint(event)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwKcmCPH0aqd",
        "outputId": "49294c06-48b6-4c52-a2fd-96aeb4782ba0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'final_answer': 'x = -\\\\frac{15}{4}',\n",
            " 'steps': [{'explanation': \"Start by isolating the term with the variable 'x'. \"\n",
            "                           'We need to move the constant term on the left side '\n",
            "                           'to the right side. To do this, subtract 7 from '\n",
            "                           'both sides of the equation.',\n",
            "            'output': '8x + 7 - 7 = -23 - 7'},\n",
            "           {'explanation': 'This simplifies to:', 'output': '8x = -30'},\n",
            "           {'explanation': \"Next, solve for 'x' by dividing both sides of the \"\n",
            "                           'equation by 8.',\n",
            "            'output': '\\\\( x = \\\\frac{-30}{8} \\\\)'},\n",
            "           {'explanation': 'Simplify the fraction by dividing the numerator '\n",
            "                           'and the denominator by their greatest common '\n",
            "                           'divisor, which is 2.',\n",
            "            'output': '\\\\( x = \\\\frac{-15}{4} \\\\)'},\n",
            "           {'explanation': 'Thus, the solution to the equation is:',\n",
            "            'output': 'x = -\\\\frac{15}{4}'}]}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import pprint\n",
        "\n",
        "# Structured Outputs for chain-of-thought math tutoring\n",
        "\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o-2024-08-06\",\n",
        "    input=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful math tutor. Guide the user through the solution step by step.\"},\n",
        "        {\"role\": \"user\", \"content\": \"how can I solve 8x + 7 = -23\"}\n",
        "    ],\n",
        "    text={\n",
        "        \"format\": {\n",
        "            \"type\": \"json_schema\",\n",
        "            \"name\": \"math_reasoning\",\n",
        "            \"schema\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"steps\": {\n",
        "                        \"type\": \"array\",\n",
        "                        \"items\": {\n",
        "                            \"type\": \"object\",\n",
        "                            \"properties\": {\n",
        "                                \"explanation\": { \"type\": \"string\" },\n",
        "                                \"output\": { \"type\": \"string\" }\n",
        "                            },\n",
        "                            \"required\": [\"explanation\", \"output\"],\n",
        "                            \"additionalProperties\": False\n",
        "                        }\n",
        "                    },\n",
        "                    \"final_answer\": { \"type\": \"string\" }\n",
        "                },\n",
        "                \"required\": [\"steps\", \"final_answer\"],\n",
        "                \"additionalProperties\": False\n",
        "            },\n",
        "            \"strict\": True\n",
        "        }\n",
        "    }\n",
        ")\n",
        "\n",
        "math_reasoning = json.loads(response.output_text)\n",
        "pprint.pprint(math_reasoning)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "0_wx1b6icjRC",
        "R9EqlFSZ7KwI",
        "1ze4WZy6BXAm",
        "WO2VNtBAv3rw"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "347559df903540dd8ff69da3e85ec63b": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_79315cdbf90341ed97d2c17b8f0b7051",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">▰▰▰▰▱▱▱</span> Thinking...\n<span style=\"color: #008080; text-decoration-color: #008080\">┏━ Message ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓</span>\n<span style=\"color: #008080; text-decoration-color: #008080\">┃</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">┃</span>\n<span style=\"color: #008080; text-decoration-color: #008080\">┃</span> <span style=\"color: #008000; text-decoration-color: #008000\">Show me a list of title from top 5 most recent story from Hacker News</span>                                           <span style=\"color: #008080; text-decoration-color: #008080\">┃</span>\n<span style=\"color: #008080; text-decoration-color: #008080\">┃</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">┃</span>\n<span style=\"color: #008080; text-decoration-color: #008080\">┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛</span>\n<span style=\"color: #808000; text-decoration-color: #808000\">┏━ Tool Calls ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓</span>\n<span style=\"color: #808000; text-decoration-color: #808000\">┃</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">┃</span>\n<span style=\"color: #808000; text-decoration-color: #808000\">┃</span> • get_top_hackernews_stories(num_stories=5)                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">┃</span>\n<span style=\"color: #808000; text-decoration-color: #808000\">┃</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">┃</span>\n<span style=\"color: #808000; text-decoration-color: #808000\">┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┏━ Response (7.3s) ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> Here are the top 5 most recent stories from Hacker News:                                                        <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">OpenAI adds MCP support to Agents SDK</span>                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span><a href=\"https://openai.github.io/openai-agents-python/mcp/\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; text-decoration: underline\">Read more</span></a>                                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">Debian bookworm live images now reproducible</span>                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span><a href=\"https://lwn.net/Articles/1015402/\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; text-decoration: underline\">Read more</span></a>                                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 3 </span><span style=\"font-weight: bold\">The Mysterious Flow of Fluid in the Brain</span>                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span><a href=\"https://www.quantamagazine.org/the-mysterious-flow-of-fluid-in-the-brain-20250326/\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; text-decoration: underline\">Read more</span></a>                                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 4 </span><span style=\"font-weight: bold\">A love letter to the CSV format</span>                                                                              <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span><a href=\"https://github.com/medialab/xan/blob/master/docs/LOVE_LETTER.md\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; text-decoration: underline\">Read more</span></a>                                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 5 </span><span style=\"font-weight: bold\">Building a Linux Container Runtime from Scratch</span>                                                              <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span><a href=\"https://edera.dev/stories/styrolite\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; text-decoration: underline\">Read more</span></a>                                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> Stay tuned for more tech tidbits! 🖥️🔍                                                                           <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛</span>\n</pre>\n",
                  "text/plain": "\u001b[32m▰▰▰▰▱▱▱\u001b[0m Thinking...\n\u001b[36m┏━\u001b[0m\u001b[36m Message \u001b[0m\u001b[36m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[36m━┓\u001b[0m\n\u001b[36m┃\u001b[0m                                                                                                                 \u001b[36m┃\u001b[0m\n\u001b[36m┃\u001b[0m \u001b[32mShow me a list of title from top 5 most recent story from Hacker News\u001b[0m                                           \u001b[36m┃\u001b[0m\n\u001b[36m┃\u001b[0m                                                                                                                 \u001b[36m┃\u001b[0m\n\u001b[36m┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\u001b[0m\n\u001b[33m┏━\u001b[0m\u001b[33m Tool Calls \u001b[0m\u001b[33m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[33m━┓\u001b[0m\n\u001b[33m┃\u001b[0m                                                                                                                 \u001b[33m┃\u001b[0m\n\u001b[33m┃\u001b[0m • get_top_hackernews_stories(num_stories=5)                                                                     \u001b[33m┃\u001b[0m\n\u001b[33m┃\u001b[0m                                                                                                                 \u001b[33m┃\u001b[0m\n\u001b[33m┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\u001b[0m\n\u001b[34m┏━\u001b[0m\u001b[34m Response (7.3s) \u001b[0m\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[34m━┓\u001b[0m\n\u001b[34m┃\u001b[0m                                                                                                                 \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m Here are the top 5 most recent stories from Hacker News:                                                        \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m                                                                                                                 \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m \u001b[1;33m 1 \u001b[0m\u001b[1mOpenAI adds MCP support to Agents SDK\u001b[0m                                                                        \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m \u001b[1;33m   \u001b[0m\u001b]8;id=501521;https://openai.github.io/openai-agents-python/mcp/\u001b\\\u001b[4;34mRead more\u001b[0m\u001b]8;;\u001b\\                                                                                                    \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m \u001b[1;33m 2 \u001b[0m\u001b[1mDebian bookworm live images now reproducible\u001b[0m                                                                 \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m \u001b[1;33m   \u001b[0m\u001b]8;id=698136;https://lwn.net/Articles/1015402/\u001b\\\u001b[4;34mRead more\u001b[0m\u001b]8;;\u001b\\                                                                                                    \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m \u001b[1;33m 3 \u001b[0m\u001b[1mThe Mysterious Flow of Fluid in the Brain\u001b[0m                                                                    \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m \u001b[1;33m   \u001b[0m\u001b]8;id=599249;https://www.quantamagazine.org/the-mysterious-flow-of-fluid-in-the-brain-20250326/\u001b\\\u001b[4;34mRead more\u001b[0m\u001b]8;;\u001b\\                                                                                                    \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m \u001b[1;33m 4 \u001b[0m\u001b[1mA love letter to the CSV format\u001b[0m                                                                              \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m \u001b[1;33m   \u001b[0m\u001b]8;id=801033;https://github.com/medialab/xan/blob/master/docs/LOVE_LETTER.md\u001b\\\u001b[4;34mRead more\u001b[0m\u001b]8;;\u001b\\                                                                                                    \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m \u001b[1;33m 5 \u001b[0m\u001b[1mBuilding a Linux Container Runtime from Scratch\u001b[0m                                                              \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m \u001b[1;33m   \u001b[0m\u001b]8;id=180920;https://edera.dev/stories/styrolite\u001b\\\u001b[4;34mRead more\u001b[0m\u001b]8;;\u001b\\                                                                                                    \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m                                                                                                                 \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m Stay tuned for more tech tidbits! 🖥️🔍                                                                           \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m                                                                                                                 \u001b[34m┃\u001b[0m\n\u001b[34m┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\u001b[0m\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "79315cdbf90341ed97d2c17b8f0b7051": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
