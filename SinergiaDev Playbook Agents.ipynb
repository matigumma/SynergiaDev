{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPWEhGa0m2SU"
      },
      "source": [
        "**Sinergia Dev** playbook base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Rg0qWBno1O4"
      },
      "source": [
        "# Openai Responses API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUiDqKuHo8xO"
      },
      "source": [
        "- python install requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UYfa5CfsoicL",
        "outputId": "15c7ca6c-fae1-4c12-a5df-603a3d0706b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in ./.venv/lib/python3.11/site-packages (1.76.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.11/site-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.11/site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.11/site-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.11/site-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in ./.venv/lib/python3.11/site-packages (from openai) (2.11.3)\n",
            "Requirement already satisfied: sniffio in ./.venv/lib/python3.11/site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.11/site-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in ./.venv/lib/python3.11/site-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiDdYIHeb--6",
        "outputId": "297b111a-31c7-4e0e-9ed6-c7f6599a55aa"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "# set env for openai key:\n",
        "\n",
        "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "P9h03_IfpSGE",
        "outputId": "0b1c90be-371f-4987-c584-6fb6397196d4"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import pprint\n",
        "client = OpenAI()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ze4WZy6BXAm"
      },
      "source": [
        "# Agents: Human in the loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSGMBhKv58lr"
      },
      "outputs": [],
      "source": [
        "# https://github.com/agno-agi/agno"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "eMRAe3Rt7bU2",
        "outputId": "fc584537-d8f0-4d17-88f0-012e6edecc3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: httpx in ./.venv/lib/python3.11/site-packages (0.28.1)\n",
            "Requirement already satisfied: rich in ./.venv/lib/python3.11/site-packages (14.0.0)\n",
            "Requirement already satisfied: agno in ./.venv/lib/python3.11/site-packages (1.4.1)\n",
            "Requirement already satisfied: anyio in ./.venv/lib/python3.11/site-packages (from httpx) (4.9.0)\n",
            "Requirement already satisfied: certifi in ./.venv/lib/python3.11/site-packages (from httpx) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.11/site-packages (from httpx) (1.0.8)\n",
            "Requirement already satisfied: idna in ./.venv/lib/python3.11/site-packages (from httpx) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx) (0.14.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.11/site-packages (from rich) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.11/site-packages (from rich) (2.19.1)\n",
            "Requirement already satisfied: docstring-parser in ./.venv/lib/python3.11/site-packages (from agno) (0.16)\n",
            "Requirement already satisfied: gitpython in ./.venv/lib/python3.11/site-packages (from agno) (3.1.44)\n",
            "Requirement already satisfied: pydantic-settings in ./.venv/lib/python3.11/site-packages (from agno) (2.9.1)\n",
            "Requirement already satisfied: pydantic in ./.venv/lib/python3.11/site-packages (from agno) (2.11.3)\n",
            "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.11/site-packages (from agno) (1.1.0)\n",
            "Requirement already satisfied: python-multipart in ./.venv/lib/python3.11/site-packages (from agno) (0.0.20)\n",
            "Requirement already satisfied: pyyaml in ./.venv/lib/python3.11/site-packages (from agno) (6.0.2)\n",
            "Requirement already satisfied: tomli in ./.venv/lib/python3.11/site-packages (from agno) (2.2.1)\n",
            "Requirement already satisfied: typer in ./.venv/lib/python3.11/site-packages (from agno) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.11/site-packages (from agno) (4.13.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich) (0.1.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.11/site-packages (from anyio->httpx) (1.3.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in ./.venv/lib/python3.11/site-packages (from gitpython->agno) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.11/site-packages (from pydantic->agno) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in ./.venv/lib/python3.11/site-packages (from pydantic->agno) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.11/site-packages (from pydantic->agno) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in ./.venv/lib/python3.11/site-packages (from typer->agno) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in ./.venv/lib/python3.11/site-packages (from typer->agno) (1.5.4)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in ./.venv/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython->agno) (5.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install httpx rich agno"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537,
          "referenced_widgets": [
            "347559df903540dd8ff69da3e85ec63b",
            "79315cdbf90341ed97d2c17b8f0b7051"
          ]
        },
        "collapsed": true,
        "id": "W6lpRf05AiX7",
        "outputId": "48bfd5e0-1bb0-42e2-e3c7-cbaee7190e0d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Setting default model to OpenAI Chat                                                                          \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[34mINFO\u001b[0m Setting default model to OpenAI Chat                                                                          \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/admin/CascadeProjects/windsurf-project/sinergia-dev/.venv/lib/python3.11/site-packages/rich/live.py:231: \n",
              "UserWarning: install \"ipywidgets\" for Jupyter support\n",
              "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
              "</pre>\n"
            ],
            "text/plain": [
              "/Users/admin/CascadeProjects/windsurf-project/sinergia-dev/.venv/lib/python3.11/site-packages/rich/live.py:231: \n",
              "UserWarning: install \"ipywidgets\" for Jupyter support\n",
              "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "About to run <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">get_top_hackernews_stories</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "About to run \u001b[1;34mget_top_hackernews_stories\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Do you want to continue? <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">[y/n]</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">(y)</span>: </pre>\n"
            ],
            "text/plain": [
              "Do you want to continue? \u001b[1;35m[y/n]\u001b[0m \u001b[1;36m(y)\u001b[0m: "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\"\"\"🤝 Human-in-the-Loop: Adding User Confirmation to Tool Calls\n",
        "\n",
        "This example shows how to implement human-in-the-loop functionality in your Agno tools.\n",
        "It shows how to:\n",
        "- Add pre-hooks to tools for user confirmation\n",
        "- Handle user input during tool execution\n",
        "- Gracefully cancel operations based on user choice\n",
        "\n",
        "Some practical applications:\n",
        "- Confirming sensitive operations before execution\n",
        "- Reviewing API calls before they're made\n",
        "- Validating data transformations\n",
        "- Approving automated actions in critical systems\n",
        "\n",
        "Run `pip install openai httpx rich agno` to install dependencies.\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "from textwrap import dedent\n",
        "from typing import Iterator\n",
        "\n",
        "import httpx\n",
        "from agno.agent import Agent\n",
        "from agno.exceptions import StopAgentRun\n",
        "from agno.tools import FunctionCall, tool\n",
        "from rich.console import Console\n",
        "from rich.pretty import pprint\n",
        "from rich.prompt import Prompt\n",
        "\n",
        "# This is the console instance used by the print_response method\n",
        "# We can use this to stop and restart the live display and ask for user confirmation\n",
        "console = Console()\n",
        "\n",
        "\n",
        "def pre_hook(fc: FunctionCall):\n",
        "    # Get the live display instance from the console\n",
        "    live = console._live\n",
        "\n",
        "    # Stop the live display temporarily so we can ask for user confirmation\n",
        "    live.stop()  # type: ignore\n",
        "\n",
        "    # Ask for confirmation\n",
        "    console.print(f\"\\nAbout to run [bold blue]{fc.function.name}[/]\")\n",
        "    message = (\n",
        "        Prompt.ask(\"Do you want to continue?\", choices=[\"y\", \"n\"], default=\"y\")\n",
        "        .strip()\n",
        "        .lower()\n",
        "    )\n",
        "\n",
        "    # Restart the live display\n",
        "    live.start()  # type: ignore\n",
        "\n",
        "    # If the user does not want to continue, raise a StopExecution exception\n",
        "    if message != \"y\":\n",
        "        raise StopAgentRun(\n",
        "            \"Tool call cancelled by user\",\n",
        "            agent_message=\"Stopping execution as permission was not granted.\",\n",
        "        )\n",
        "\n",
        "\n",
        "@tool(pre_hook=pre_hook)\n",
        "def get_top_hackernews_stories(num_stories: int) -> Iterator[str]:\n",
        "    \"\"\"Fetch top stories from Hacker News after user confirmation.\n",
        "\n",
        "    Args:\n",
        "        num_stories (int): Number of stories to retrieve\n",
        "\n",
        "    Returns:\n",
        "        str: JSON string containing story details\n",
        "    \"\"\"\n",
        "    # Fetch top story IDs\n",
        "    response = httpx.get(\"https://hacker-news.firebaseio.com/v0/topstories.json\")\n",
        "    story_ids = response.json()\n",
        "\n",
        "    # Yield story details\n",
        "    for story_id in story_ids[:num_stories]:\n",
        "        story_response = httpx.get(\n",
        "            f\"https://hacker-news.firebaseio.com/v0/item/{story_id}.json\"\n",
        "        )\n",
        "        story = story_response.json()\n",
        "        if \"text\" in story:\n",
        "            story.pop(\"text\", None)\n",
        "        yield json.dumps(story)\n",
        "\n",
        "\n",
        "# Initialize the agent with a tech-savvy personality and clear instructions\n",
        "agent = Agent(\n",
        "    description=\"A Tech News Assistant that fetches and summarizes Hacker News stories\",\n",
        "    instructions=dedent(\"\"\"\\\n",
        "        You are an enthusiastic Tech Reporter\n",
        "\n",
        "        Your responsibilities:\n",
        "        - Present Hacker News stories in an engaging and informative way\n",
        "        - Provide clear summaries of the information you gather\n",
        "\n",
        "        Style guide:\n",
        "        - Use emoji to make your responses more engaging\n",
        "        - Keep your summaries concise but informative\n",
        "        - End with a friendly tech-themed sign-off\\\n",
        "    \"\"\"),\n",
        "    tools=[get_top_hackernews_stories],\n",
        "    show_tool_calls=True,\n",
        "    markdown=True,\n",
        ")\n",
        "\n",
        "# Example questions to try:\n",
        "# - \"What are the top 3 HN stories right now?\"\n",
        "# - \"Show me the most recent story from Hacker News\"\n",
        "# - \"Get the top 5 stories (you can try accepting and declining the confirmation)\"\n",
        "agent.print_response(\n",
        "    \"Show me a list of title from top 5 most recent story from Hacker News\", stream=True, console=console\n",
        ")\n",
        "\n",
        "# View all messages\n",
        "# pprint(agent.run_response.messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH3MRILz7OBs"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WO2VNtBAv3rw"
      },
      "source": [
        "# Memory w/mem0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwBuIBKh5y3V"
      },
      "outputs": [],
      "source": [
        "# https://github.com/mem0ai/mem0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jN9IF8aR7gMq"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QhEgL0oov_rM",
        "outputId": "a2c31c7a-510c-49e6-a8fd-258c1ac4f2a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mem0ai\n",
            "  Downloading mem0ai-0.1.93-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.33.0 in ./.venv/lib/python3.11/site-packages (from mem0ai) (1.76.0)\n",
            "Collecting posthog<4.0.0,>=3.5.0 (from mem0ai)\n",
            "  Downloading posthog-3.25.0-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting psycopg2-binary<3.0.0,>=2.9.10 (from mem0ai)\n",
            "  Downloading psycopg2_binary-2.9.10-cp311-cp311-macosx_14_0_arm64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.3 in ./.venv/lib/python3.11/site-packages (from mem0ai) (2.11.3)\n",
            "Collecting pytz<2025.0,>=2024.1 (from mem0ai)\n",
            "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting qdrant-client<2.0.0,>=1.9.1 (from mem0ai)\n",
            "  Downloading qdrant_client-1.14.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: sqlalchemy<3.0.0,>=2.0.31 in ./.venv/lib/python3.11/site-packages (from mem0ai) (2.0.40)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.33.0->mem0ai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.33.0->mem0ai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.33.0->mem0ai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.33.0->mem0ai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in ./.venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.33.0->mem0ai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.33.0->mem0ai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in ./.venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.33.0->mem0ai) (4.13.2)\n",
            "Requirement already satisfied: requests<3.0,>=2.7 in ./.venv/lib/python3.11/site-packages (from posthog<4.0.0,>=3.5.0->mem0ai) (2.32.3)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from posthog<4.0.0,>=3.5.0->mem0ai) (1.17.0)\n",
            "Collecting monotonic>=1.5 (from posthog<4.0.0,>=3.5.0->mem0ai)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog<4.0.0,>=3.5.0->mem0ai)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: python-dateutil>2.1 in ./.venv/lib/python3.11/site-packages (from posthog<4.0.0,>=3.5.0->mem0ai) (2.9.0.post0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.3->mem0ai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in ./.venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.3->mem0ai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.3->mem0ai) (0.4.0)\n",
            "Collecting grpcio>=1.41.0 (from qdrant-client<2.0.0,>=1.9.1->mem0ai)\n",
            "  Downloading grpcio-1.71.0-cp311-cp311-macosx_10_14_universal2.whl.metadata (3.8 kB)\n",
            "Collecting numpy>=1.21 (from qdrant-client<2.0.0,>=1.9.1->mem0ai)\n",
            "  Downloading numpy-2.2.5-cp311-cp311-macosx_14_0_arm64.whl.metadata (62 kB)\n",
            "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant-client<2.0.0,>=1.9.1->mem0ai)\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting protobuf>=3.20.0 (from qdrant-client<2.0.0,>=1.9.1->mem0ai)\n",
            "  Downloading protobuf-6.30.2-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.14 in ./.venv/lib/python3.11/site-packages (from qdrant-client<2.0.0,>=1.9.1->mem0ai) (2.4.0)\n",
            "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.33.0->mem0ai) (3.10)\n",
            "Requirement already satisfied: certifi in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.33.0->mem0ai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.33.0->mem0ai) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.33.0->mem0ai) (0.14.0)\n",
            "Collecting h2<5,>=3 (from httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai)\n",
            "  Downloading h2-4.2.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests<3.0,>=2.7->posthog<4.0.0,>=3.5.0->mem0ai) (3.4.1)\n",
            "Collecting hyperframe<7,>=6.1 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai)\n",
            "  Downloading hyperframe-6.1.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting hpack<5,>=4.1 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai)\n",
            "  Downloading hpack-4.1.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Downloading mem0ai-0.1.93-py3-none-any.whl (136 kB)\n",
            "Downloading posthog-3.25.0-py2.py3-none-any.whl (89 kB)\n",
            "Downloading psycopg2_binary-2.9.10-cp311-cp311-macosx_14_0_arm64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
            "Downloading qdrant_client-1.14.1-py3-none-any.whl (327 kB)\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading grpcio-1.71.0-cp311-cp311-macosx_10_14_universal2.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:01\u001b[0mm\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading numpy-2.2.5-cp311-cp311-macosx_14_0_arm64.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Downloading protobuf-6.30.2-cp39-abi3-macosx_10_9_universal2.whl (417 kB)\n",
            "Downloading h2-4.2.0-py3-none-any.whl (60 kB)\n",
            "Downloading hpack-4.1.0-py3-none-any.whl (34 kB)\n",
            "Downloading hyperframe-6.1.0-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: pytz, monotonic, psycopg2-binary, protobuf, portalocker, numpy, hyperframe, hpack, grpcio, backoff, posthog, h2, qdrant-client, mem0ai\n",
            "Successfully installed backoff-2.2.1 grpcio-1.71.0 h2-4.2.0 hpack-4.1.0 hyperframe-6.1.0 mem0ai-0.1.93 monotonic-1.6 numpy-2.2.5 portalocker-2.10.1 posthog-3.25.0 protobuf-6.30.2 psycopg2-binary-2.9.10 pytz-2024.2 qdrant-client-1.14.1\n"
          ]
        }
      ],
      "source": [
        "!pip install mem0ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nf5KVXmzwBAI",
        "outputId": "a3b1001b-64f5-4573-833e-0be74791f6be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chat with AI (type 'exit' to quit)\n",
            "AI: ¡Hola Matías! Es un placer conocerte. ¿En qué puedo ayudarte hoy?\n",
            "AI: Te faltan 10 años para cumplir 40.\n",
            "AI: Sé que te llamas Matías y que tienes 30 años porque lo compartiste anteriormente. ¿Hay algo más que te gustaría contarme o preguntar?\n"
          ]
        },
        {
          "ename": "BadRequestError",
          "evalue": "Error code: 400 - {'error': {'message': \"'$.input' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     32\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAI: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchat_with_memories(user_input)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 32\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     30\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mGoodbye!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     31\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAI: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mchat_with_memories\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mchat_with_memories\u001b[39m\u001b[34m(message, user_id)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchat_with_memories\u001b[39m(message: \u001b[38;5;28mstr\u001b[39m, user_id: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mdefault_user\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# Retrieve relevant memories\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     relevant_memories = \u001b[43mmemory\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m     memories_str = \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mentry[\u001b[33m'\u001b[39m\u001b[33mmemory\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m relevant_memories[\u001b[33m\"\u001b[39m\u001b[33mresults\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     12\u001b[39m     \u001b[38;5;66;03m# Generate Assistant response\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/CascadeProjects/windsurf-project/sinergia-dev/.venv/lib/python3.11/site-packages/mem0/memory/main.py:512\u001b[39m, in \u001b[36mMemory.search\u001b[39m\u001b[34m(self, query, user_id, agent_id, run_id, limit, filters)\u001b[39m\n\u001b[32m    504\u001b[39m     future_graph_entities = (\n\u001b[32m    505\u001b[39m         executor.submit(\u001b[38;5;28mself\u001b[39m.graph.search, query, filters, limit) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.enable_graph \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    506\u001b[39m     )\n\u001b[32m    508\u001b[39m     concurrent.futures.wait(\n\u001b[32m    509\u001b[39m         [future_memories, future_graph_entities] \u001b[38;5;28;01mif\u001b[39;00m future_graph_entities \u001b[38;5;28;01melse\u001b[39;00m [future_memories]\n\u001b[32m    510\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m512\u001b[39m     original_memories = \u001b[43mfuture_memories\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    513\u001b[39m     graph_entities = future_graph_entities.result() \u001b[38;5;28;01mif\u001b[39;00m future_graph_entities \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    515\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.enable_graph:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-macos-aarch64-none/lib/python3.11/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-macos-aarch64-none/lib/python3.11/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-macos-aarch64-none/lib/python3.11/concurrent/futures/thread.py:58\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/CascadeProjects/windsurf-project/sinergia-dev/.venv/lib/python3.11/site-packages/mem0/memory/main.py:531\u001b[39m, in \u001b[36mMemory._search_vector_store\u001b[39m\u001b[34m(self, query, filters, limit)\u001b[39m\n\u001b[32m    530\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_search_vector_store\u001b[39m(\u001b[38;5;28mself\u001b[39m, query, filters, limit):\n\u001b[32m--> \u001b[39m\u001b[32m531\u001b[39m     embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membedding_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msearch\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    532\u001b[39m     memories = \u001b[38;5;28mself\u001b[39m.vector_store.search(query=query, vectors=embeddings, limit=limit, filters=filters)\n\u001b[32m    534\u001b[39m     excluded_keys = {\n\u001b[32m    535\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33muser_id\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    536\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33magent_id\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    542\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    543\u001b[39m     }\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/CascadeProjects/windsurf-project/sinergia-dev/.venv/lib/python3.11/site-packages/mem0/embeddings/openai.py:46\u001b[39m, in \u001b[36mOpenAIEmbedding.embed\u001b[39m\u001b[34m(self, text, memory_action)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[33;03mGet the embedding for the given text using OpenAI.\u001b[39;00m\n\u001b[32m     37\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     42\u001b[39m \u001b[33;03m    list: The embedding vector.\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     44\u001b[39m text = text.replace(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdimensions\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding_dims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m     .data[\u001b[32m0\u001b[39m]\n\u001b[32m     48\u001b[39m     .embedding\n\u001b[32m     49\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/CascadeProjects/windsurf-project/sinergia-dev/.venv/lib/python3.11/site-packages/openai/resources/embeddings.py:128\u001b[39m, in \u001b[36mEmbeddings.create\u001b[39m\u001b[34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    122\u001b[39m             embedding.embedding = np.frombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[32m    123\u001b[39m                 base64.b64decode(data), dtype=\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    124\u001b[39m             ).tolist()\n\u001b[32m    126\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/embeddings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/CascadeProjects/windsurf-project/sinergia-dev/.venv/lib/python3.11/site-packages/openai/_base_client.py:1239\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1225\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1226\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1227\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1234\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1235\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1236\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1237\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1238\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1239\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/CascadeProjects/windsurf-project/sinergia-dev/.venv/lib/python3.11/site-packages/openai/_base_client.py:1034\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1031\u001b[39m             err.response.read()\n\u001b[32m   1033\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1034\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1036\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': \"'$.input' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "from mem0 import Memory\n",
        "\n",
        "openai_client = OpenAI()\n",
        "memory = Memory()\n",
        "\n",
        "def chat_with_memories(message: str, user_id: str = \"default_user\") -> str:\n",
        "    # Retrieve relevant memories\n",
        "    relevant_memories = memory.search(query=message, user_id=user_id, limit=3)\n",
        "    memories_str = \"\\n\".join(f\"- {entry['memory']}\" for entry in relevant_memories[\"results\"])\n",
        "\n",
        "    # Generate Assistant response\n",
        "    system_prompt = f\"You are a helpful AI. Answer the question based on query and memories.\\nUser Memories:\\n{memories_str}\"\n",
        "    messages = [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": message}]\n",
        "    # Completion API\n",
        "    response = openai_client.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
        "    assistant_response = response.choices[0].message.content\n",
        "\n",
        "    # Create new memories from the conversation\n",
        "    messages.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
        "    memory.add(messages, user_id=user_id)\n",
        "\n",
        "    return assistant_response\n",
        "\n",
        "def main():\n",
        "    print(\"Chat with AI (type 'exit' to quit)\")\n",
        "    while True:\n",
        "        user_input = input(\"You: \").strip()\n",
        "        if user_input.lower() == 'exit':\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "        print(f\"AI: {chat_with_memories(user_input)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "0_wx1b6icjRC",
        "R9EqlFSZ7KwI",
        "1ze4WZy6BXAm",
        "WO2VNtBAv3rw"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "347559df903540dd8ff69da3e85ec63b": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_79315cdbf90341ed97d2c17b8f0b7051",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">▰▰▰▰▱▱▱</span> Thinking...\n<span style=\"color: #008080; text-decoration-color: #008080\">┏━ Message ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓</span>\n<span style=\"color: #008080; text-decoration-color: #008080\">┃</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">┃</span>\n<span style=\"color: #008080; text-decoration-color: #008080\">┃</span> <span style=\"color: #008000; text-decoration-color: #008000\">Show me a list of title from top 5 most recent story from Hacker News</span>                                           <span style=\"color: #008080; text-decoration-color: #008080\">┃</span>\n<span style=\"color: #008080; text-decoration-color: #008080\">┃</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">┃</span>\n<span style=\"color: #008080; text-decoration-color: #008080\">┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛</span>\n<span style=\"color: #808000; text-decoration-color: #808000\">┏━ Tool Calls ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓</span>\n<span style=\"color: #808000; text-decoration-color: #808000\">┃</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">┃</span>\n<span style=\"color: #808000; text-decoration-color: #808000\">┃</span> • get_top_hackernews_stories(num_stories=5)                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">┃</span>\n<span style=\"color: #808000; text-decoration-color: #808000\">┃</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">┃</span>\n<span style=\"color: #808000; text-decoration-color: #808000\">┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┏━ Response (7.3s) ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> Here are the top 5 most recent stories from Hacker News:                                                        <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">OpenAI adds MCP support to Agents SDK</span>                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span><a href=\"https://openai.github.io/openai-agents-python/mcp/\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; text-decoration: underline\">Read more</span></a>                                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">Debian bookworm live images now reproducible</span>                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span><a href=\"https://lwn.net/Articles/1015402/\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; text-decoration: underline\">Read more</span></a>                                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 3 </span><span style=\"font-weight: bold\">The Mysterious Flow of Fluid in the Brain</span>                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span><a href=\"https://www.quantamagazine.org/the-mysterious-flow-of-fluid-in-the-brain-20250326/\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; text-decoration: underline\">Read more</span></a>                                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 4 </span><span style=\"font-weight: bold\">A love letter to the CSV format</span>                                                                              <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span><a href=\"https://github.com/medialab/xan/blob/master/docs/LOVE_LETTER.md\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; text-decoration: underline\">Read more</span></a>                                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 5 </span><span style=\"font-weight: bold\">Building a Linux Container Runtime from Scratch</span>                                                              <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span><a href=\"https://edera.dev/stories/styrolite\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; text-decoration: underline\">Read more</span></a>                                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span> Stay tuned for more tech tidbits! 🖥️🔍                                                                           <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┃</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">┃</span>\n<span style=\"color: #000080; text-decoration-color: #000080\">┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛</span>\n</pre>\n",
                  "text/plain": "\u001b[32m▰▰▰▰▱▱▱\u001b[0m Thinking...\n\u001b[36m┏━\u001b[0m\u001b[36m Message \u001b[0m\u001b[36m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[36m━┓\u001b[0m\n\u001b[36m┃\u001b[0m                                                                                                                 \u001b[36m┃\u001b[0m\n\u001b[36m┃\u001b[0m \u001b[32mShow me a list of title from top 5 most recent story from Hacker News\u001b[0m                                           \u001b[36m┃\u001b[0m\n\u001b[36m┃\u001b[0m                                                                                                                 \u001b[36m┃\u001b[0m\n\u001b[36m┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\u001b[0m\n\u001b[33m┏━\u001b[0m\u001b[33m Tool Calls \u001b[0m\u001b[33m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[33m━┓\u001b[0m\n\u001b[33m┃\u001b[0m                                                                                                                 \u001b[33m┃\u001b[0m\n\u001b[33m┃\u001b[0m • get_top_hackernews_stories(num_stories=5)                                                                     \u001b[33m┃\u001b[0m\n\u001b[33m┃\u001b[0m                                                                                                                 \u001b[33m┃\u001b[0m\n\u001b[33m┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\u001b[0m\n\u001b[34m┏━\u001b[0m\u001b[34m Response (7.3s) \u001b[0m\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[34m━┓\u001b[0m\n\u001b[34m┃\u001b[0m                                                                                                                 \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m Here are the top 5 most recent stories from Hacker News:                                                        \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m                                                                                                                 \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m \u001b[1;33m 1 \u001b[0m\u001b[1mOpenAI adds MCP support to Agents SDK\u001b[0m                                                                        \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m \u001b[1;33m   \u001b[0m\u001b]8;id=501521;https://openai.github.io/openai-agents-python/mcp/\u001b\\\u001b[4;34mRead more\u001b[0m\u001b]8;;\u001b\\                                                                                                    \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m \u001b[1;33m 2 \u001b[0m\u001b[1mDebian bookworm live images now reproducible\u001b[0m                                                                 \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m \u001b[1;33m   \u001b[0m\u001b]8;id=698136;https://lwn.net/Articles/1015402/\u001b\\\u001b[4;34mRead more\u001b[0m\u001b]8;;\u001b\\                                                                                                    \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m \u001b[1;33m 3 \u001b[0m\u001b[1mThe Mysterious Flow of Fluid in the Brain\u001b[0m                                                                    \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m \u001b[1;33m   \u001b[0m\u001b]8;id=599249;https://www.quantamagazine.org/the-mysterious-flow-of-fluid-in-the-brain-20250326/\u001b\\\u001b[4;34mRead more\u001b[0m\u001b]8;;\u001b\\                                                                                                    \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m \u001b[1;33m 4 \u001b[0m\u001b[1mA love letter to the CSV format\u001b[0m                                                                              \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m \u001b[1;33m   \u001b[0m\u001b]8;id=801033;https://github.com/medialab/xan/blob/master/docs/LOVE_LETTER.md\u001b\\\u001b[4;34mRead more\u001b[0m\u001b]8;;\u001b\\                                                                                                    \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m \u001b[1;33m 5 \u001b[0m\u001b[1mBuilding a Linux Container Runtime from Scratch\u001b[0m                                                              \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m \u001b[1;33m   \u001b[0m\u001b]8;id=180920;https://edera.dev/stories/styrolite\u001b\\\u001b[4;34mRead more\u001b[0m\u001b]8;;\u001b\\                                                                                                    \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m                                                                                                                 \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m Stay tuned for more tech tidbits! 🖥️🔍                                                                           \u001b[34m┃\u001b[0m\n\u001b[34m┃\u001b[0m                                                                                                                 \u001b[34m┃\u001b[0m\n\u001b[34m┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\u001b[0m\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "79315cdbf90341ed97d2c17b8f0b7051": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
